[["index.html", "R Code for Causal Inference: What If Welcome How to install required R packages How to download dataset Source for this book", " R Code for Causal Inference: What If Bill Behrman Welcome This book provides R code for Hernán and Robins, Causal Inference: What If. The linked site has a PDF of the book. You can run the code from this book on your computer by ensuring that you have the required R packages and by downloading the dataset used in chapters 12-17, as explained below. You can easily copy a block of code into your clipboard by hovering over it and then clicking the copy button that appears in the upper-right corner. How to install required R packages The following will install the R packages used in this book. install.packages( c( &quot;tidyverse&quot;, &quot;boot&quot;, &quot;fs&quot;, &quot;geepack&quot;, &quot;here&quot;, &quot;ivreg&quot;, &quot;kableExtra&quot;, &quot;knitr&quot;, &quot;multcomp&quot;, &quot;remotes&quot;, &quot;scales&quot;, &quot;survival&quot; ) ) How to download dataset To download the dataset used in chapters 12-17, first set your working directory to where you plan to run code. You can see your current working directory with getwd(), and you can set your working directory with setwd(). If you plan to run code within an RStudio project, set the directory to the root directory of the project. Next, run the following. It will create a subdirectory named data, if one doesn’t already exist, and then download the dataset into it. url_nhefs &lt;- &quot;https://raw.githubusercontent.com/behrman/ci-wi/master/data/nhefs.rds&quot; fs::dir_create(&quot;data&quot;) download.file(url = url_nhefs, destfile = &quot;data/nhefs.rds&quot;) Source for this book The source for this book is available on GitHub where we welcome suggestions for improvements. This work is licensed under a Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. "],["11.html", "11 Why Model? 11.1 Data cannot speak for themselves 11.2 Parametric estimators of the conditional mean 11.3 Nonparametric estimators of the conditional mean 11.4 Smoothing", " 11 Why Model? # Packages library(tidyverse) # Round and format vector round_format &lt;- function(x, nsmall = 2, ...) { format(round(x, digits = nsmall), nsmall = nsmall, ...) } # Print tibble kable &lt;- function(x, cols = where(is.double), nsmall = 2, align = &quot;r&quot;, ...) { x %&gt;% mutate(across({{cols}}, round_format, nsmall = nsmall)) %&gt;% knitr::kable(align = align, ...) %&gt;% kableExtra::kable_styling(full_width = FALSE, position = &quot;left&quot;) } 11.1 Data cannot speak for themselves Dataset 1. data_1 &lt;- tibble( A = as.factor(c(1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0)), Y = c(200, 150, 220, 110, 50, 180, 90, 170, 170, 30, 70, 110, 80, 50, 10, 20) ) Figure 11.1. data_1_means &lt;- data_1 %&gt;% group_by(A) %&gt;% summarize(Y = mean(Y)) data_1 %&gt;% ggplot(aes(A, Y)) + geom_point() + geom_point(data = data_1_means, color = &quot;red&quot;) + labs( title = &quot;Figure 11.1&quot;, subtitle = &quot;Sample means are in red&quot; ) Sample means for levels of A. kable(data_1_means) A Y 0 67.50 1 146.25 Dataset 2. data_2 &lt;- tibble( A = as.factor(c(1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3, 4, 4, 4, 4)), Y = c(110, 80, 50, 40, 170, 30, 70, 50, 110, 50, 180, 130, 200, 150, 220, 210) ) Figure 11.2. data_2_means &lt;- data_2 %&gt;% group_by(A) %&gt;% summarize(Y = mean(Y)) data_2 %&gt;% ggplot(aes(A, Y)) + geom_point() + geom_point(data = data_2_means, color = &quot;red&quot;) + labs( title = &quot;Figure 11.2&quot;, subtitle = &quot;Sample means are in red&quot; ) Sample means for levels of A. kable(data_2_means, nsmall = 1) A Y 1 70.0 2 80.0 3 117.5 4 195.0 Dataset 3. data_3 &lt;- tibble( A = c(3, 11, 17, 23, 29, 37, 41, 53, 67, 79, 83, 97, 60, 71, 15, 45), Y = c( 21, 54, 33, 101, 85, 65, 157, 120, 111, 200, 140, 220, 230, 217, 11, 190 ) ) Figure 11.3. data_3 %&gt;% ggplot(aes(A, Y)) + geom_point() + labs(title = &quot;Figure 11.3&quot;) 11.2 Parametric estimators of the conditional mean Fit linear regression. fit &lt;- lm(Y ~ A, data = data_3) broom::tidy(fit, conf.int = TRUE) %&gt;% select(term, estimate, conf_low = conf.low, conf_high = conf.high) %&gt;% kable(align = &quot;lrrr&quot;) term estimate conf_low conf_high (Intercept) 24.55 -21.20 70.29 A 2.14 1.28 2.99 Figure 11.4. data_3 %&gt;% ggplot(aes(A, Y)) + geom_point() + geom_abline(slope = coef(fit)[&quot;A&quot;], intercept = coef(fit)[&quot;(Intercept)&quot;]) + labs(title = &quot;Figure 11.4&quot;) Predicted value of E[Y | A = 90] with 95% confidence interval. predict(fit, newdata = tibble(A = 90), interval = &quot;confidence&quot;) %&gt;% as_tibble() %&gt;% rename(estimate = fit, conf_low = lwr, conf_high = upr) %&gt;% kable(nsmall = 1) estimate conf_low conf_high 216.9 172.1 261.6 11.3 Nonparametric estimators of the conditional mean Fit linear regression. fit &lt;- lm(Y ~ A, data = data_1) broom::tidy(fit) %&gt;% select(term, estimate) %&gt;% kable(align = &quot;lr&quot;) term estimate (Intercept) 67.50 A1 78.75 Estimates of E[Y | A] for A = 0 and A = 1. tibble( A = as.factor(0:1), Y = predict(fit, newdata = tibble(A)) ) %&gt;% kable() A Y 0 67.50 1 146.25 11.4 Smoothing Fit linear regression with quadratic term. fit &lt;- lm(Y ~ A + I(A^2), data = data_3) broom::tidy(fit) %&gt;% select(term, estimate) %&gt;% kable(align = &quot;lr&quot;) term estimate (Intercept) -7.41 A 4.11 I(A^2) -0.02 Figure 11.5. line &lt;- tibble( A = seq(min(data_3$A), max(data_3$A), length.out = 201), Y = predict(fit, newdata = tibble(A)) ) data_3 %&gt;% ggplot(aes(A, Y)) + geom_point() + geom_line(data = line) + labs(title = &quot;Figure 11.5&quot;) Predicted value of E[Y | A = 90] with 95% confidence interval. predict(fit, newdata = tibble(A = 90), interval = &quot;confidence&quot;) %&gt;% as_tibble() %&gt;% rename(estimate = fit, conf_low = lwr, conf_high = upr) %&gt;% kable(nsmall = 1) estimate conf_low conf_high 197.1 142.8 251.5 "],["12.html", "12 IP weighting and marginal structural models 12.1 The causal question 12.2 Estimating IP weights via modeling 12.3 Stabilized IP weights 12.4 Marginal structural models 12.5 Effect modification and marginal structural models 12.6 Censoring and missing data", " 12 IP weighting and marginal structural models # Packages library(tidyverse) # Parameters # NHEFS data file_nhefs &lt;- here::here(&quot;data/nhefs.rds&quot;) # Round and format vector round_format &lt;- function(x, nsmall = 2, ...) { format(round(x, digits = nsmall), nsmall = nsmall, ...) } # Print tibble kable &lt;- function(x, cols = where(is.double), nsmall = 2, align = &quot;r&quot;, ...) { x %&gt;% mutate(across({{cols}}, round_format, nsmall = nsmall)) %&gt;% knitr::kable(align = align, ...) %&gt;% kableExtra::kable_styling(full_width = FALSE, position = &quot;left&quot;) } # Print min, mean, and max of vector kable_summary &lt;- function(x, nsmall = 2, ...) { tibble(min = min(x), mean = mean(x), max = max(x)) %&gt;% kable(nsmall = nsmall, ...) } #=============================================================================== # NHEFS data nhefs &lt;- read_rds(file_nhefs) # NHEFS censored for those with weight measurements in 1982 nhefs_censored &lt;- nhefs %&gt;% drop_na(wt82, wt82_71) 12.1 The causal question The data are from the National Health and Nutrition Examination Survey 1 Epidemiologic Follow-up Study (NHEFS). The data are drawn from two questionnaires, one taken in 1971 and the other in 1982. Below we will be using these variables: active: In your usual day, how active are you? in 1971 0: Very active 1: Moderately active 2: Inactive age: Age in 1971 death: Death by 1992 0: No 1: Yes education: Amount of education by 1971 1: 8th grade or less 2: High school dropout 3: High school 4: College dropout 5: College or more exercise: In recreation, how much exercise? in 1971 0: Much exercise 1: Moderate exercise 2: Little or no exercise qsmk: Quit smoking between 1971 and 1982 questionnaires 0: No 1: Yes race: Race in 1971 0: White 1: Black or other sex: Sex 0: Male 1: Female smokeintensity: Number of cigarettes smoked per day in 1971 smokeintensity82_71: Increase in number of cigarettes smoked per day between 1971 and 1982 smokeyrs: Years of smoking wt71: Weight in 1971 (kilograms) wt82: Weight in 1982 (kilograms) wt82_71: Weight change between 1971 and 1982 (kilograms) The causal question is: What is the average causal effect of smoking cessation (qsmk) on weight gain (wt82_71)? In the following, we will examine the censored dataset of those with weight measurements in 1982. Number of people in dataset. nrow(nhefs_censored) #&gt; [1] 1566 Range of ages. range(nhefs_censored$age) #&gt; [1] 25 74 Average weight gains in quitters and non-quitters. v &lt;- nhefs_censored %&gt;% group_by(qsmk) %&gt;% summarize(across(wt82_71, mean)) kable(v, nsmall = 1) qsmk wt82_71 0 2.0 1 4.5 The average weight gain was 2.0 kg in non-quitters and 4.5 kg in quitters. Create a simple linear model to get an estimate the difference in average weight gains with a 95% confidence interval. fit &lt;- lm(wt82_71 ~ qsmk, data = nhefs_censored) broom::tidy(fit, conf.int = TRUE) %&gt;% filter(term == &quot;qsmk1&quot;) %&gt;% select(estimate, conf_low = conf.low, conf_high = conf.high) %&gt;% kable(nsmall = 1) estimate conf_low conf_high 2.5 1.7 3.4 Table 12.1. var_descriptions &lt;- c( age = &quot;Age (years)&quot;, male = &quot;Men (%)&quot;, white = &quot;White (%)&quot;, university = &quot;University (%)&quot;, wt71 = &quot;Weight (kg)&quot;, smokeintensity = &quot;Cigarettes per day&quot;, smokeyrs = &quot;Years smoking&quot;, little_exercise = &quot;Little exercise (%)&quot;, inactive = &quot;Inactive life (%)&quot; ) nhefs_censored %&gt;% transmute( qsmk, age, male = sex == &quot;0&quot;, white = race == &quot;0&quot;, university = education == &quot;5&quot;, wt71, smokeintensity, smokeyrs, little_exercise = exercise == &quot;2&quot;, inactive = active == &quot;2&quot; ) %&gt;% group_by(qsmk) %&gt;% summarize(across(everything(), mean)) %&gt;% mutate( across(c(male, white, university, little_exercise, inactive), ~ 100 * .) ) %&gt;% pivot_longer(cols = !qsmk, names_to = &quot;Mean baseline characteristics&quot;) %&gt;% pivot_wider(names_from = qsmk, names_prefix = &quot;A = &quot;) %&gt;% mutate(across(`Mean baseline characteristics`, ~ var_descriptions[.])) %&gt;% relocate(`A = 0`, .after = `A = 1`) %&gt;% kable(nsmall = 1, align = &quot;lrr&quot;) Mean baseline characteristics A = 1 A = 0 Age (years) 46.2 42.8 Men (%) 54.6 46.6 White (%) 91.1 85.4 University (%) 15.4 9.9 Weight (kg) 72.4 70.3 Cigarettes per day 18.6 21.2 Years smoking 26.0 24.1 Little exercise (%) 40.7 37.9 Inactive life (%) 11.2 8.9 12.2 Estimating IP weights via modeling Fit logistic regression model for propensity scores. fit &lt;- glm( qsmk ~ sex + poly(age, 2) + race + education + poly(wt71, 2) + poly(smokeintensity, 2) + poly(smokeyrs, 2) + active + exercise, family = binomial(), data = nhefs_censored ) Non-stabilized IP weights for treatment. ip_w_a &lt;- case_when( nhefs_censored$qsmk == &quot;0&quot; ~ 1 / (1 - predict(fit, type = &quot;response&quot;)), nhefs_censored$qsmk == &quot;1&quot; ~ 1 / predict(fit, type = &quot;response&quot;), TRUE ~ NA_real_ ) kable_summary(ip_w_a) min mean max 1.05 2.00 16.70 Estimate average treatment effect (ATE) using weighted least squares. This is a valid method for estimating the ATE but not its standard error. fit_lm &lt;- lm(wt82_71 ~ qsmk, data = nhefs_censored, weights = ip_w_a) broom::tidy(fit_lm) #&gt; # A tibble: 2 × 5 #&gt; term estimate std.error statistic p.value #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 (Intercept) 1.78 0.288 6.18 8.40e-10 #&gt; 2 qsmk1 3.44 0.408 8.43 7.47e-17 Estimate ATE and its standard error using generalized estimating equation model. fit_geeglm &lt;- geepack::geeglm( wt82_71 ~ qsmk, data = nhefs_censored, weights = ip_w_a, id = seqn ) broom::tidy(fit_geeglm) #&gt; # A tibble: 2 × 5 #&gt; term estimate std.error statistic p.value #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 (Intercept) 1.78 0.225 62.7 2.33e-15 #&gt; 2 qsmk1 3.44 0.525 42.9 5.86e-11 The two estimates for the ATE are very close. ate_lm &lt;- coef(fit_lm)[[&quot;qsmk1&quot;]] ate_geeglm &lt;- coef(fit_geeglm)[[&quot;qsmk1&quot;]] ate_lm - ate_geeglm #&gt; [1] 3.996803e-15 Estimate of ATE with 95% confidence interval. v &lt;- broom::tidy(fit_geeglm, conf.int = TRUE) %&gt;% filter(term == &quot;qsmk1&quot;) %&gt;% select(estimate, conf_low = conf.low, conf_high = conf.high) kable(v, nsmall = 1) estimate conf_low conf_high 3.4 2.4 4.5 Plot treatment levels for each confounder. plot_treatment &lt;- function(var, weights, bins = 25) { v &lt;- nhefs_censored %&gt;% mutate(weights = weights) %&gt;% count({{var}}, qsmk, wt = weights) if (is.factor(pull(nhefs_censored, {{var}}))) { v %&gt;% ggplot(aes({{var}}, n)) + geom_col(aes(fill = qsmk), position = &quot;dodge&quot;) } else if (is.numeric(pull(nhefs_censored, {{var}}))) { v %&gt;% ggplot(aes({{var}})) + geom_freqpoly(aes(color = qsmk, weight = n), bins = bins) } else { NULL } } confounders &lt;- vars( sex, age, race, education, smokeintensity, smokeyrs, active, exercise, wt71 ) confounders %&gt;% map(plot_treatment, weights = ip_w_a) %&gt;% walk(print) In the pseudo-population with nonstabilized IP weighting, the treatment populations are roughly equal. 12.3 Stabilized IP weights Stabilized IP weights for treatment. ip_sw_a &lt;- case_when( nhefs_censored$qsmk == &quot;0&quot; ~ 1 - mean(nhefs_censored$qsmk == &quot;1&quot;), nhefs_censored$qsmk == &quot;1&quot; ~ mean(nhefs_censored$qsmk == &quot;1&quot;), TRUE ~ NA_real_ ) * ip_w_a kable_summary(ip_sw_a) min mean max 0.33 1.00 4.30 Estimate ATE and its standard error using generalized estimating equation model. fit_geeglm &lt;- geepack::geeglm( wt82_71 ~ qsmk, data = nhefs_censored, weights = ip_sw_a, id = seqn ) broom::tidy(fit_geeglm) #&gt; # A tibble: 2 × 5 #&gt; term estimate std.error statistic p.value #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 (Intercept) 1.78 0.225 62.7 2.33e-15 #&gt; 2 qsmk1 3.44 0.525 42.9 5.86e-11 Estimate of ATE with 95% confidence interval. v &lt;- broom::tidy(fit_geeglm, conf.int = TRUE) %&gt;% filter(term == &quot;qsmk1&quot;) %&gt;% select(estimate, conf_low = conf.low, conf_high = conf.high) kable(v, nsmall = 1) estimate conf_low conf_high 3.4 2.4 4.5 Plot treatment levels for each confounder. confounders %&gt;% map(plot_treatment, weights = ip_sw_a) %&gt;% walk(print) In the pseudo-population with stabilized IP weighting, the treatment populations are now unequal. These populations reflect the fact that approximately 74.3% of the participants did not quit smoking (qsmk = 0) and 25.7% of the participants did (qsmk = 1). Fine Point 12.2 Checking positivity Count number of individuals in all combinations of sex, age, and qsmk. v &lt;- nhefs_censored %&gt;% expand(sex, age = full_seq(age, period = 1), qsmk) %&gt;% left_join( nhefs_censored %&gt;% mutate(n = 1), by = c(&quot;sex&quot;, &quot;age&quot;, &quot;qsmk&quot;) ) %&gt;% count(sex, age, qsmk, wt = n) v #&gt; # A tibble: 200 × 4 #&gt; sex age qsmk n #&gt; &lt;fct&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 0 25 0 20 #&gt; 2 0 25 1 6 #&gt; 3 0 26 0 21 #&gt; 4 0 26 1 5 #&gt; 5 0 27 0 11 #&gt; 6 0 27 1 5 #&gt; 7 0 28 0 22 #&gt; 8 0 28 1 3 #&gt; 9 0 29 0 18 #&gt; 10 0 29 1 2 #&gt; # … with 190 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows Number of combinations by number of individuals in combination. v %&gt;% ggplot(aes(n)) + geom_bar() + labs( title = &quot;Number of combinations by number of individuals in combination&quot;, x = &quot;Number of individuals in combination&quot;, y = &quot;Number of combinations&quot; ) Eleven combinations have no individuals. v %&gt;% filter(n == 0) %&gt;% kable(nsmall = 0) sex age qsmk n 0 71 1 0 0 73 0 0 0 73 1 0 0 74 0 0 1 66 1 0 1 67 1 0 1 68 1 0 1 71 0 0 1 73 0 0 1 73 1 0 1 74 0 0 12.4 Marginal structural models In this section, we will estimate the causal effect of the change in smoking intensity (smkintensity82_71), a continuous variable, on the average weight gain (wt82_71). Distribution of smokeintensity. nhefs_censored %&gt;% ggplot(aes(smokeintensity)) + geom_histogram(binwidth = 5, boundary = 0) + labs(title = &quot;Distribution of smokeintensity&quot;) Create subset of data with individuals who smoked 25 or fewer cigarettes per day at baseline. nhefs_censored_smoke_25 &lt;- nhefs_censored %&gt;% filter(smokeintensity &lt;= 25) Number of individuals in subset. nrow(nhefs_censored_smoke_25) #&gt; [1] 1162 Numerator for IP weights. treatment &lt;- nhefs_censored_smoke_25$smkintensity82_71 ip_numerator &lt;- dnorm(treatment, mean = mean(treatment), sd = sd(treatment)) The numerator for the IP weights approximates smkintensity82_71 with a normal distribution. Here is the actual distribution of smkintensity82_71 with its normal approximation. normal_approx &lt;- tibble( x = seq(min(treatment), max(treatment), length.out = 201), y = dnorm(x, mean = mean(treatment), sd = sd(treatment)) ) nhefs_censored_smoke_25 %&gt;% ggplot() + geom_histogram( aes(smkintensity82_71, stat(density)), binwidth = 5, boundary = 0 ) + geom_line(aes(x, y), data = normal_approx, color = &quot;red&quot;) + labs( title = &quot;Distribution of smokeintensity82_71&quot;, subtitle = &quot;With normal approximation in red&quot; ) Denominator for IP weights. fit &lt;- lm( smkintensity82_71 ~ sex + poly(age, 2) + race + education + poly(wt71, 2) + poly(smokeintensity, 2) + poly(smokeyrs, 2) + active + exercise, data = nhefs_censored_smoke_25 ) ip_denominator &lt;- dnorm(treatment, mean = predict(fit, type = &quot;response&quot;), sd = sigma(fit)) IP weights for marginal structural model. ip_msm &lt;- ip_numerator / ip_denominator kable_summary(ip_msm) min mean max 0.19 1.00 5.10 Fit marginal structural model. fit &lt;- geepack::geeglm( wt82_71 ~ smkintensity82_71 + I(smkintensity82_71^2), data = nhefs_censored_smoke_25, weights = ip_msm, id = seqn ) broom::tidy(fit) #&gt; # A tibble: 3 × 5 #&gt; term estimate std.error statistic p.value #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 (Intercept) 2.00 0.295 46.1 1.10e-11 #&gt; 2 smkintensity82_71 -0.109 0.0315 11.9 5.48e- 4 #&gt; 3 I(smkintensity82_71^2) 0.00269 0.00242 1.24 2.65e- 1 Coefficients of model. broom::tidy(fit) %&gt;% select(term, estimate) %&gt;% kable(nsmall = 3, align = &quot;lr&quot;) term estimate (Intercept) 2.005 smkintensity82_71 -0.109 I(smkintensity82_71^2) 0.003 Mean weight gain with 95% confidence interval for constant smoking intensity. broom::tidy(fit, conf.int = TRUE) %&gt;% filter(term == &quot;(Intercept)&quot;) %&gt;% select(estimate, conf_low = conf.low, conf_high = conf.high) %&gt;% kable(nsmall = 1) estimate conf_low conf_high 2.0 1.4 2.6 Mean weight gain with 95% confidence interval for increase in smoking intensity of 20 cigarettes per day. fit &lt;- geepack::geeglm( wt82_71 ~ I(smkintensity82_71 - 20) + I((smkintensity82_71 - 20)^2), data = nhefs_censored_smoke_25, weights = ip_msm, id = seqn ) broom::tidy(fit, conf.int = TRUE) %&gt;% filter(term == &quot;(Intercept)&quot;) %&gt;% select(estimate, conf_low = conf.low, conf_high = conf.high) %&gt;% kable(nsmall = 1) estimate conf_low conf_high 0.9 -1.7 3.5 Marginal structural model for causal effect of quitting smoking (qsmk) on the risk of death by 1992 (death). For this calculation, we will convert the type of qsmk and death from factor to double. fit &lt;- nhefs_censored %&gt;% mutate(across(c(qsmk, death), ~ as.double(.) - 1)) %&gt;% geepack::geeglm( death ~ qsmk, family = binomial(), data = ., weights = ip_sw_a, id = seqn ) broom::tidy(fit) #&gt; # A tibble: 2 × 5 #&gt; term estimate std.error statistic p.value #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 (Intercept) -1.49 0.0789 356. 0 #&gt; 2 qsmk 0.0301 0.157 0.0367 0.848 Estimate of causal odds ratio with 95% confidence interval. broom::tidy(fit, conf.int = TRUE, exponentiate = TRUE) %&gt;% filter(term == &quot;qsmk&quot;) %&gt;% select(estimate, conf_low = conf.low, conf_high = conf.high) %&gt;% kable(nsmall = 1) estimate conf_low conf_high 1.0 0.8 1.4 12.5 Effect modification and marginal structural models IP weights. fit &lt;- glm(qsmk ~ sex, family = binomial(), data = nhefs_censored) ip_sw_a &lt;- case_when( nhefs_censored$qsmk == &quot;0&quot; ~ (1 - predict(fit, type = &quot;response&quot;)), nhefs_censored$qsmk == &quot;1&quot; ~ predict(fit, type = &quot;response&quot;), TRUE ~ NA_real_ ) * ip_w_a kable_summary(ip_sw_a) min mean max 0.29 1.00 3.80 Fit marginal structural model. fit &lt;- geepack::geeglm( wt82_71 ~ qsmk * sex, data = nhefs_censored, weights = ip_sw_a, id = seqn ) broom::tidy(fit) #&gt; # A tibble: 4 × 5 #&gt; term estimate std.error statistic p.value #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 (Intercept) 1.78 0.310 33.2 0.00000000845 #&gt; 2 qsmk1 3.52 0.657 28.7 0.0000000832 #&gt; 3 sex1 -0.00872 0.449 0.000378 0.984 #&gt; 4 qsmk1:sex1 -0.159 1.05 0.0232 0.879 Estimate of effect modification by sex. broom::tidy(fit, conf.int = TRUE) %&gt;% filter(term == &quot;qsmk1:sex1&quot;) %&gt;% select(estimate, conf_low = conf.low, conf_high = conf.high) %&gt;% kable(nsmall = 1) estimate conf_low conf_high -0.2 -2.2 1.9 12.6 Censoring and missing data Number of individuals in full dataset. nrow(nhefs) #&gt; [1] 1629 Number of individuals whose weight in 1982 is missing. sum(is.na(nhefs$wt82)) #&gt; [1] 63 Add censored variable to nhefs to indicate whether or not weight in 1982 (wt82) is missing. nhefs &lt;- nhefs %&gt;% mutate(censored = if_else(!is.na(wt82), 0, 1) %&gt;% as.factor()) The treatment qsmk is associated with censoring. v &lt;- nhefs %&gt;% group_by(qsmk) %&gt;% summarize(censored = mean(censored == &quot;1&quot;)) kable(v, nsmall = 3) qsmk censored 0 0.032 1 0.058 3.2% of non-quitters were censored versus 5.8% of quitters. The predictor wt71 is also associated with censoring. v &lt;- nhefs %&gt;% group_by(censored) %&gt;% summarize(across(wt71, mean)) kable(v, nsmall = 1) censored wt71 0 70.8 1 76.6 The average baseline weight was 70.8 kg in the uncensored versus 76.6 kg in the censored. Stabilized IP weights for treatment. ip_numerator &lt;- case_when( nhefs$qsmk == &quot;0&quot; ~ 1 - mean(nhefs$qsmk == &quot;1&quot;), nhefs$qsmk == &quot;1&quot; ~ mean(nhefs$qsmk == &quot;1&quot;), TRUE ~ NA_real_ ) fit_denominator &lt;- glm( qsmk ~ sex + poly(age, 2) + race + education + poly(wt71, 2) + poly(smokeintensity, 2) + poly(smokeyrs, 2) + active + exercise, family = binomial(), data = nhefs ) ip_denominator &lt;- case_when( nhefs$qsmk == &quot;0&quot; ~ 1 - predict(fit_denominator, type = &quot;response&quot;), nhefs$qsmk == &quot;1&quot; ~ predict(fit_denominator, type = &quot;response&quot;), TRUE ~ NA_real_ ) ip_sw_a &lt;- ip_numerator / ip_denominator Stabilized IP weights for censoring. fit_numerator &lt;- glm(censored ~ qsmk, family = binomial(), data = nhefs) ip_numerator &lt;- case_when( nhefs$censored == &quot;0&quot; ~ 1 - predict(fit_numerator, type = &quot;response&quot;), nhefs$censored == &quot;1&quot; ~ predict(fit_numerator, type = &quot;response&quot;), TRUE ~ NA_real_ ) fit_denominator &lt;- glm( censored ~ qsmk + sex + poly(age, 2) + race + education + poly(wt71, 2) + poly(smokeintensity, 2) + poly(smokeyrs, 2) + active + exercise, family = binomial(), data = nhefs ) ip_denominator &lt;- case_when( nhefs$censored == &quot;0&quot; ~ 1 - predict(fit_denominator, type = &quot;response&quot;), nhefs$censored == &quot;1&quot; ~ predict(fit_denominator, type = &quot;response&quot;), TRUE ~ NA_real_ ) ip_sw_c &lt;- ip_numerator / ip_denominator Stabilized IP weights for treatment and censoring ip_sw_ac = ip_sw_a * ip_sw_c kable_summary(ip_sw_ac[nhefs$censored == &quot;0&quot;]) min mean max 0.35 1.00 4.09 Estimate ATE and its standard error using generalized estimating equation model. fit_geeglm &lt;- geepack::geeglm( wt82_71 ~ qsmk, data = nhefs_censored, weights = ip_sw_ac[nhefs$censored == &quot;0&quot;], id = seqn ) broom::tidy(fit_geeglm) #&gt; # A tibble: 2 × 5 #&gt; term estimate std.error statistic p.value #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 (Intercept) 1.66 0.233 51.0 9.29e-13 #&gt; 2 qsmk1 3.50 0.526 44.2 2.89e-11 Estimate of ATE with 95% confidence interval. v &lt;- broom::tidy(fit_geeglm, conf.int = TRUE) %&gt;% filter(term == &quot;qsmk1&quot;) %&gt;% select(estimate, conf_low = conf.low, conf_high = conf.high) kable(v, nsmall = 1) estimate conf_low conf_high 3.5 2.5 4.5 "],["13.html", "13 Standardization and the parametric g-formula 13.1 Standardization as an alternative to IP weighting 13.2 Estimating the mean outcome via modeling 13.3 Standardizing the mean outcome to the confounder distribution", " 13 Standardization and the parametric g-formula # Packages library(tidyverse) # Parameters # NHEFS data file_nhefs &lt;- here::here(&quot;data/nhefs.rds&quot;) # Round and format vector round_format &lt;- function(x, nsmall = 2, ...) { format(round(x, digits = nsmall), nsmall = nsmall, ...) } # Print tibble kable &lt;- function(x, cols = where(is.double), nsmall = 2, align = &quot;r&quot;, ...) { x %&gt;% mutate(across({{cols}}, round_format, nsmall = nsmall)) %&gt;% knitr::kable(align = align, ...) %&gt;% kableExtra::kable_styling(full_width = FALSE, position = &quot;left&quot;) } # Print min, mean, and max of vector kable_summary &lt;- function(x, nsmall = 2, ...) { tibble(min = min(x), mean = mean(x), max = max(x)) %&gt;% kable(nsmall = nsmall, ...) } #=============================================================================== # NHEFS data nhefs &lt;- read_rds(file_nhefs) # NHEFS censored for those with weight measurements in 1982 nhefs_censored &lt;- nhefs %&gt;% drop_na(wt82, wt82_71) 13.1 Standardization as an alternative to IP weighting Number of individuals in full dataset nrow(nhefs) #&gt; [1] 1629 Number of individuals with weight measurements in 1982. nrow(nhefs_censored) #&gt; [1] 1566 13.2 Estimating the mean outcome via modeling In this section, we will use the censored dataset of those with weight measurements in 1982. Count untreated and treated individuals. v &lt;- nhefs_censored %&gt;% count(qsmk) kable(v, nsmall = 0) qsmk n 0 1163 1 403 There are 1163 untreated individuals and 403 treated individuals. Fit linear regression model for weight gain. fit &lt;- lm( wt82_71 ~ qsmk * smokeintensity + sex + poly(age, 2) + race + education + poly(wt71, 2) + I(smokeintensity^2) + poly(smokeyrs, 2) + active + exercise, data = nhefs_censored ) broom::tidy(fit) #&gt; # A tibble: 21 × 5 #&gt; term estimate std.error statistic p.value #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 (Intercept) 1.67 0.903 1.85 0.0651 #&gt; 2 qsmk1 2.56 0.809 3.16 0.00159 #&gt; 3 smokeintensity 0.0491 0.0517 0.950 0.342 #&gt; 4 sex1 -1.43 0.469 -3.05 0.00233 #&gt; 5 poly(age, 2)1 -90.6 15.7 -5.76 0.00000000994 #&gt; 6 poly(age, 2)2 -36.2 10.2 -3.53 0.000421 #&gt; 7 race1 0.560 0.582 0.963 0.336 #&gt; 8 education2 0.790 0.607 1.30 0.193 #&gt; 9 education3 0.556 0.556 1.00 0.317 #&gt; 10 education4 1.49 0.832 1.79 0.0733 #&gt; # … with 11 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows Predict weight gain for individuals. nhefs_censored_pred &lt;- nhefs_censored %&gt;% mutate(wt82_71_pred = predict(fit)) The individual with the unique identifier 24770. v &lt;- nhefs_censored_pred %&gt;% filter(seqn == 24770) This person’s characteristics. v %&gt;% select( seqn, qsmk, sex, race, age, education, smokeintensity, smokeyrs, exercise, active, wt71 ) %&gt;% kable(nsmall = 0) %&gt;% kableExtra::scroll_box(width = &quot;100%&quot;) seqn qsmk sex race age education smokeintensity smokeyrs exercise active wt71 24770 0 0 0 26 4 15 12 1 0 112 This person was a white male who did not quit smoking. In 1971, he was age 26, a college dropout, smoked 15 cigarettes a day, had been smoking for 12 years, had moderate exercise, was very active, and weighed 112 kg. This person’s observed and predicted weight gain. v %&gt;% select(wt82_71, wt82_71_pred) %&gt;% kable() wt82_71 wt82_71_pred 3.18 0.34 The person was observed to gain 3.18 kg between 1971 and 1982 and was predicted to gain 0.34 kg. Observed weight gain for individuals. kable_summary(nhefs_censored$wt82_71, nsmall = 1) min mean max -41.3 2.6 48.5 Predicted weight gain for individuals. kable_summary(nhefs_censored_pred$wt82_71_pred, nsmall = 1) min mean max -10.9 2.6 9.9 The mean observed weight gain and the mean predicted weight gain are very close. mean(nhefs_censored$wt82_71) - mean(nhefs_censored_pred$wt82_71_pred) #&gt; [1] -1.021405e-14 Prediction residuals. nhefs_censored_pred %&gt;% ggplot(aes(wt82_71_pred, wt82_71 - wt82_71_pred)) + geom_point(alpha = 0.5) + geom_hline(yintercept = 0, color = &quot;white&quot;, size = 2) + geom_smooth(method = &quot;loess&quot;, formula = y ~ x) + labs( title = &quot;Prediction residuals&quot;, x = &quot;Predicted weight gain (kg)&quot;, y = &quot;Residual (kg)&quot; ) 13.3 Standardizing the mean outcome to the confounder distribution Data from Table 2.2. df &lt;- tribble( ~name, ~L, ~A, ~Y, &quot;Rheia&quot;, 0, 0, 0, &quot;Kronos&quot;, 0, 0, 1, &quot;Demeter&quot;, 0, 0, 0, &quot;Hades&quot;, 0, 0, 0, &quot;Hestia&quot;, 0, 1, 0, &quot;Poseidon&quot;, 0, 1, 0, &quot;Hera&quot;, 0, 1, 0, &quot;Zeus&quot;, 0, 1, 1, &quot;Artemis&quot;, 1, 0, 1, &quot;Apollo&quot;, 1, 0, 1, &quot;Leto&quot;, 1, 0, 0, &quot;Ares&quot;, 1, 1, 1, &quot;Athena&quot;, 1, 1, 1, &quot;Hephaestus&quot;, 1, 1, 1, &quot;Aphrodite&quot;, 1, 1, 1, &quot;Cyclope&quot;, 1, 1, 1, &quot;Persephone&quot;, 1, 1, 1, &quot;Hermes&quot;, 1, 1, 0, &quot;Hebe&quot;, 1, 1, 0, &quot;Dionysus&quot;, 1, 1, 0 ) %&gt;% mutate(across(c(L, A, Y), as.factor)) Fit logistic regression model for outcome Y. fit &lt;- glm(Y ~ A * L, family = binomial(), data = df) broom::tidy(fit) #&gt; # A tibble: 4 × 5 #&gt; term estimate std.error statistic p.value #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 (Intercept) -1.10e+ 0 1.15 -9.51e- 1 0.341 #&gt; 2 A1 -4.59e-16 1.63 -2.81e-16 1 #&gt; 3 L1 1.79e+ 0 1.68 1.06e+ 0 0.287 #&gt; 4 A1:L1 0 2.16 0 1 Estimate mean value of Y for each individual when untreated (A = 0) and treated (A = 1). pred_means &lt;- tibble( Y_A_0 = mean(predict(fit, newdata = df %&gt;% mutate(A = &quot;0&quot;), type = &quot;response&quot;)), Y_A_1 = mean(predict(fit, newdata = df %&gt;% mutate(A = &quot;1&quot;), type = &quot;response&quot;)) ) kable(pred_means) Y_A_0 Y_A_1 0.50 0.50 The standardized mean outcomes were 0.50 for both the untreated and treated. We’ll now use the same procedure with the NHEFS data. Fit linear regression model for weight gain. fit &lt;- lm( wt82_71 ~ qsmk * smokeintensity + sex + poly(age, 2) + race + education + poly(wt71, 2) + I(smokeintensity^2) + poly(smokeyrs, 2) + active + exercise, data = nhefs_censored ) broom::tidy(fit) #&gt; # A tibble: 21 × 5 #&gt; term estimate std.error statistic p.value #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 (Intercept) 1.67 0.903 1.85 0.0651 #&gt; 2 qsmk1 2.56 0.809 3.16 0.00159 #&gt; 3 smokeintensity 0.0491 0.0517 0.950 0.342 #&gt; 4 sex1 -1.43 0.469 -3.05 0.00233 #&gt; 5 poly(age, 2)1 -90.6 15.7 -5.76 0.00000000994 #&gt; 6 poly(age, 2)2 -36.2 10.2 -3.53 0.000421 #&gt; 7 race1 0.560 0.582 0.963 0.336 #&gt; 8 education2 0.790 0.607 1.30 0.193 #&gt; 9 education3 0.556 0.556 1.00 0.317 #&gt; 10 education4 1.49 0.832 1.79 0.0733 #&gt; # … with 11 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows Estimate mean value of weight gain for each individual (wt82_71) when untreated (qsmk = 0) and treated (qsmk = 1). pred_means &lt;- tibble( wt82_71_qsmk_0 = mean(predict(fit, newdata = nhefs %&gt;% mutate(qsmk = &quot;0&quot;))), wt82_71_qsmk_1 = mean(predict(fit, newdata = nhefs %&gt;% mutate(qsmk = &quot;1&quot;))) ) kable(pred_means) wt82_71_qsmk_0 wt82_71_qsmk_1 1.66 5.18 The standardized mean in the untreated is 1.66 kg, and the standardized mean in the treated is 5.18 kg. So the estimate for the ATE is 3.5 kg. We will now use bootstrapping to obtain a confidence interval for this estimate. ATE using fit on sample of data. ate &lt;- function(data, sample_rows) { fit &lt;- lm( wt82_71 ~ qsmk * smokeintensity + sex + poly(age, 2) + race + education + poly(wt71, 2) + I(smokeintensity^2) + poly(smokeyrs, 2) + active + exercise, data = data %&gt;% slice(sample_rows) ) mean(predict(fit, newdata = nhefs %&gt;% mutate(qsmk = &quot;1&quot;))) - mean(predict(fit, newdata = nhefs %&gt;% mutate(qsmk = &quot;0&quot;))) } Perform bootstrap resampling. set.seed(231) n_boot &lt;- 1e4 boot_out &lt;- boot::boot(data = nhefs_censored, statistic = ate, R = n_boot) Distribution of average treatment effect. tibble(ate = boot_out$t) %&gt;% ggplot(aes(ate)) + geom_histogram(binwidth = 0.1, boundary = 0) + labs( title = &quot;Distribution of average treatment effect&quot;, x = &quot;Average treatment effect&quot;, y = &quot;Count&quot; ) Estimate of ATE with 95% confidence interval calculated using bias-corrected and accelerated (BCa) method. estimate &lt;- ate(data = nhefs_censored, sample_rows = 1:nrow(nhefs_censored)) v &lt;- broom::tidy(boot_out, conf.int = TRUE, conf.method = &quot;bca&quot;) %&gt;% transmute(estimate, conf_low = conf.low, conf_high = conf.high) kable(v, nsmall = 1) estimate conf_low conf_high 3.5 2.6 4.5 "],["14.html", "14 G-estimation and structural nested models 14.1 The causal question revisited 14.4 Rank preservation 14.5 G-estimation 14.6 Structural nested models with two or more parameters", " 14 G-estimation and structural nested models # Packages library(tidyverse) # Parameters # NHEFS data file_nhefs &lt;- here::here(&quot;data/nhefs.rds&quot;) # Round and format vector round_format &lt;- function(x, nsmall = 2, ...) { format(round(x, digits = nsmall), nsmall = nsmall, ...) } # Print tibble kable &lt;- function(x, cols = where(is.double), nsmall = 2, align = &quot;r&quot;, ...) { x %&gt;% mutate(across({{cols}}, round_format, nsmall = nsmall)) %&gt;% knitr::kable(align = align, ...) %&gt;% kableExtra::kable_styling(full_width = FALSE, position = &quot;left&quot;) } # Print min, mean, and max of vector kable_summary &lt;- function(x, nsmall = 2, ...) { tibble(min = min(x), mean = mean(x), max = max(x)) %&gt;% kable(nsmall = nsmall, ...) } #=============================================================================== # NHEFS data nhefs &lt;- read_rds(file_nhefs) # NHEFS censored for those with weight measurements in 1982 nhefs_censored &lt;- nhefs %&gt;% drop_na(wt82, wt82_71) 14.1 The causal question revisited Number of people in censored dataset. nrow(nhefs_censored) #&gt; [1] 1566 Range of ages. range(nhefs_censored$age) #&gt; [1] 25 74 14.4 Rank preservation Individuals ranked first, second, and last in weight gain. nhefs_censored %&gt;% select(seqn, wt82_71) %&gt;% arrange(desc(wt82_71)) %&gt;% slice(1:2, n()) %&gt;% kable(nsmall = 1) seqn wt82_71 23522 48.5 6928 47.5 23321 -41.3 14.5 G-estimation Add censored variable to nhefs to indicate whether or not weight in 1982 (wt82) is missing. nhefs &lt;- nhefs %&gt;% mutate(censored = if_else(!is.na(wt82), 0, 1) %&gt;% as.factor()) Non-stabilized IP weights for censoring. fit &lt;- glm( censored ~ qsmk + sex + poly(age, 2) + race + education + poly(wt71, 2) + poly(smokeintensity, 2) + poly(smokeyrs, 2) + active + exercise, family = binomial(), data = nhefs ) ip_w_c &lt;- case_when( nhefs$censored == &quot;0&quot; ~ 1 / (1 - predict(fit, type = &quot;response&quot;)), nhefs$censored == &quot;1&quot; ~ 1 / predict(fit, type = &quot;response&quot;), TRUE ~ NA_real_ ) %&gt;% keep(nhefs$censored == &quot;0&quot;) kable_summary(ip_w_c) min mean max 1.00 1.04 1.82 For potential counterfactual (psi), calculate logistic regression coefficient (alpha) and its p-value (p_value). g_est &lt;- function(psi) { geepack::geeglm( qsmk ~ sex + poly(age, 2) + race + education + poly(wt71, 2) + poly(smokeintensity, 2) + poly(smokeyrs, 2) + active + exercise + h, family = binomial(), data = nhefs_censored %&gt;% mutate( qsmk = as.double(qsmk) - 1, h = wt82_71 - psi * qsmk ), weights = ip_w_c, id = seqn ) %&gt;% broom::tidy() %&gt;% filter(term == &quot;h&quot;) %&gt;% transmute(psi, alpha = estimate, p_value = p.value) } Calculate alpha for potential counterfactuals between 2.0 and 5.0 in increments of 0.1. v &lt;- seq(2, 5, 0.1) %&gt;% map_dfr(g_est) v #&gt; # A tibble: 31 × 3 #&gt; psi alpha p_value #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2 0.0267 0.00177 #&gt; 2 2.1 0.0249 0.00358 #&gt; 3 2.2 0.0231 0.00696 #&gt; 4 2.3 0.0212 0.0130 #&gt; 5 2.4 0.0194 0.0234 #&gt; 6 2.5 0.0176 0.0404 #&gt; 7 2.6 0.0157 0.0670 #&gt; 8 2.7 0.0139 0.107 #&gt; 9 2.8 0.0120 0.163 #&gt; 10 2.9 0.0102 0.239 #&gt; # … with 21 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows The two values of psi with alpha values closest to 0. v %&gt;% select(psi, alpha) %&gt;% slice_min(n = 2, abs(alpha)) %&gt;% knitr::kable(digits = 3) %&gt;% kableExtra::kable_styling(full_width = FALSE, position = &quot;left&quot;) psi alpha 3.4 0.001 3.5 -0.001 Estimate of ATE with 95% confidence interval. v %&gt;% summarize( estimate = min(psi[abs(alpha) == min(abs(alpha))]), conf_low = max(psi[psi &lt; estimate &amp; p_value &lt; 0.05]), conf_high = min(psi[psi &gt; estimate &amp; p_value &lt; 0.05]) ) %&gt;% kable(nsmall = 1) estimate conf_low conf_high 3.4 2.5 4.5 P-value as a function of potential counterfactual. v &lt;- seq(2, 5, 0.01) %&gt;% map_dfr(g_est) v %&gt;% ggplot(aes(psi, p_value)) + geom_line() + geom_hline(yintercept = 0.05, color = &quot;red&quot;) + scale_x_continuous(minor_breaks = scales::breaks_width(0.1)) + labs( title = &quot;P-value as a function of potential counterfactual&quot;, subtitle = &quot;Red line indicates p-value = 0.05&quot;, x = &quot;Potential counterfactual&quot;, y = &quot;P-value&quot; ) For a better estimate of the ATE, use optimization to search for the value of psi with alpha value closest to 0. f &lt;- function(psi) { abs(g_est(psi)$alpha) } v &lt;- optimize(f, interval = c(3.4, 3.5)) estimate &lt;- v$minimum tibble(estimate, `abs(alpha)` = v$objective) %&gt;% kable(nsmall = 3) estimate abs(alpha) 3.446 0.000 For a better estimate of the lower bound of the 95% confidence interval, use optimization to search for the smaller value of psi with p-value value closest to 0.05. f &lt;- function(psi) { abs(g_est(psi)$p_value - 0.05) } v &lt;- optimize(f, interval = c(2.5, 2.6)) conf_low &lt;- v$minimum tibble(conf_low, `abs(p_value - 0.05)` = v$objective) %&gt;% kable(nsmall = 3) conf_low abs(p_value - 0.05) 2.541 0.000 For a better estimate of the upper bound of the 95% confidence interval, use optimization to search for the larger value of psi with p-value value closest to 0.05. v &lt;- optimize(f, interval = c(4.4, 4.5)) conf_high &lt;- v$minimum tibble(conf_high, `abs(p_value - 0.05)` = v$objective) %&gt;% kable(nsmall = 3) conf_high abs(p_value - 0.05) 4.406 0.000 Using the formula in Technical Point 14.2, we obtain a closed-form estimate of the ATE. fit &lt;- glm( qsmk ~ sex + poly(age, 2) + race + education + poly(wt71, 2) + poly(smokeintensity, 2) + poly(smokeyrs, 2) + active + exercise, family = binomial(), data = nhefs_censored, weights = ip_w_c ) broom::tidy(fit) #&gt; # A tibble: 19 × 5 #&gt; term estimate std.error statistic p.value #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 (Intercept) -1.17 0.199 -5.85 0.00000000490 #&gt; 2 sex1 -0.514 0.150 -3.42 0.000622 #&gt; 3 poly(age, 2)1 22.1 4.77 4.64 0.00000348 #&gt; 4 poly(age, 2)2 -4.51 3.05 -1.48 0.140 #&gt; 5 race1 -0.861 0.206 -4.18 0.0000293 #&gt; 6 education2 -0.0289 0.193 -0.150 0.881 #&gt; 7 education3 0.0877 0.173 0.507 0.612 #&gt; 8 education4 0.0664 0.266 0.249 0.803 #&gt; 9 education5 0.471 0.221 2.13 0.0331 #&gt; 10 poly(wt71, 2)1 3.43 2.59 1.33 0.185 #&gt; # … with 9 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows v &lt;- nhefs_censored %&gt;% mutate( qsmk = as.double(qsmk) - 1, qsmk_pred = predict(fit, type = &quot;response&quot;), ) %&gt;% summarize( estimate = sum(ip_w_c * wt82_71 * (qsmk - qsmk_pred)) / sum(ip_w_c * qsmk * (qsmk - qsmk_pred)) ) kable(v, nsmall = 3) estimate 3.446 14.6 Structural nested models with two or more parameters The estimate for the ATE if we assume that it depends upon the baseline level of smoking intensity (smokeintensity). v &lt;- nhefs_censored %&gt;% mutate( qsmk = as.double(qsmk) - 1, qsmk_pred = predict(fit, type = &quot;response&quot;), a_1 = ip_w_c * qsmk * (qsmk - qsmk_pred), a_2 = a_1 * smokeintensity, a_3 = a_1 * smokeintensity^2, b_1 = ip_w_c * wt82_71 * (qsmk - qsmk_pred), b_2 = b_1 * smokeintensity ) %&gt;% summarize(across(starts_with(c(&quot;a_&quot;, &quot;b_&quot;)), sum)) a &lt;- matrix(c(v$a_1, v$a_2, v$a_2, v$a_3), nrow = 2) b &lt;- matrix(c(v$b_1, v$b_2), nrow = 2) v &lt;- solve(a, b) tibble(psi_1 = v[1, 1], psi_2 = v[2, 1]) %&gt;% kable() psi_1 psi_2 2.86 0.03 "],["15.html", "15 Outcome regression and propensity scores 15.1 Outcome regression 15.2 Propensity scores 15.3 Propensity stratification and standardization", " 15 Outcome regression and propensity scores # Packages library(tidyverse) # Parameters # NHEFS data file_nhefs &lt;- here::here(&quot;data/nhefs.rds&quot;) # Round and format vector round_format &lt;- function(x, nsmall = 2, ...) { format(round(x, digits = nsmall), nsmall = nsmall, ...) } # Print tibble kable &lt;- function(x, cols = where(is.double), nsmall = 2, align = &quot;r&quot;, ...) { x %&gt;% mutate(across({{cols}}, round_format, nsmall = nsmall)) %&gt;% knitr::kable(align = align, ...) %&gt;% kableExtra::kable_styling(full_width = FALSE, position = &quot;left&quot;) } #=============================================================================== # NHEFS data nhefs &lt;- read_rds(file_nhefs) # NHEFS censored for those with weight measurements in 1982 nhefs_censored &lt;- nhefs %&gt;% drop_na(wt82, wt82_71) 15.1 Outcome regression Fit linear regression using same model as in 13.2. fit &lt;- lm( wt82_71 ~ qsmk * smokeintensity + sex + poly(age, 2) + race + education + poly(wt71, 2) + I(smokeintensity^2) + poly(smokeyrs, 2) + active + exercise, data = nhefs_censored ) broom::tidy(fit) #&gt; # A tibble: 21 × 5 #&gt; term estimate std.error statistic p.value #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 (Intercept) 1.67 0.903 1.85 0.0651 #&gt; 2 qsmk1 2.56 0.809 3.16 0.00159 #&gt; 3 smokeintensity 0.0491 0.0517 0.950 0.342 #&gt; 4 sex1 -1.43 0.469 -3.05 0.00233 #&gt; 5 poly(age, 2)1 -90.6 15.7 -5.76 0.00000000994 #&gt; 6 poly(age, 2)2 -36.2 10.2 -3.53 0.000421 #&gt; 7 race1 0.560 0.582 0.963 0.336 #&gt; 8 education2 0.790 0.607 1.30 0.193 #&gt; 9 education3 0.556 0.556 1.00 0.317 #&gt; 10 education4 1.49 0.832 1.79 0.0733 #&gt; # … with 11 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows Estimates for coefficients of qsmk1 and qsmk1:smokeintensity. broom::tidy(fit) %&gt;% filter(term %in% c(&quot;qsmk1&quot;, &quot;qsmk1:smokeintensity&quot;)) %&gt;% select(term, estimate) %&gt;% kable(nsmall = 2, align = &quot;lr&quot;) term estimate qsmk1 2.56 qsmk1:smokeintensity 0.05 Use multcomp::glht() to estimate ATE with 95% confidence interval. ate &lt;- function(fit, contrast) { linfct &lt;- matrix(0, ncol = length(coef(fit))) colnames(linfct) &lt;- names(coef(fit)) linfct[, names(contrast)] &lt;- contrast multcomp::glht(fit, linfct = linfct) %&gt;% broom::tidy(conf.int = TRUE) %&gt;% select(estimate, conf_low = conf.low, conf_high = conf.high) } Estimate ATE with 95% confidence interval for the effect of quitting smoking 5 cigarettes per day vs. not quitting. ate(fit, contrast = c(qsmk1 = 1, `qsmk1:smokeintensity` = 5)) %&gt;% kable(nsmall = 1) estimate conf_low conf_high 2.8 1.5 4.1 Estimate ATE with 95% confidence interval for the effect of quitting smoking 40 cigarettes per day vs. not quitting. ate(fit, contrast = c(qsmk1 = 1, `qsmk1:smokeintensity` = 40)) %&gt;% kable(nsmall = 1) estimate conf_low conf_high 4.4 2.8 6.1 Fit linear regression without product terms, the same model as in 13.3. fit &lt;- lm( wt82_71 ~ qsmk + sex + poly(age, 2) + race + education + poly(wt71, 2) + poly(smokeintensity, 2) + poly(smokeyrs, 2) + active + exercise, data = nhefs_censored ) broom::tidy(fit) #&gt; # A tibble: 20 × 5 #&gt; term estimate std.error statistic p.value #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 (Intercept) 2.09 0.628 3.33 8.75e- 4 #&gt; 2 qsmk1 3.46 0.438 7.90 5.36e-15 #&gt; 3 sex1 -1.47 0.468 -3.13 1.79e- 3 #&gt; 4 poly(age, 2)1 -90.7 15.7 -5.77 9.51e- 9 #&gt; 5 poly(age, 2)2 -36.4 10.2 -3.56 3.89e- 4 #&gt; 6 race1 0.586 0.582 1.01 3.14e- 1 #&gt; 7 education2 0.819 0.607 1.35 1.78e- 1 #&gt; 8 education3 0.572 0.556 1.03 3.04e- 1 #&gt; 9 education4 1.51 0.832 1.81 7.01e- 2 #&gt; 10 education5 -0.171 0.741 -0.230 8.18e- 1 #&gt; # … with 10 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows Estimate of ATE with 95% confidence interval. v &lt;- broom::tidy(fit, conf.int = TRUE) %&gt;% filter(term == &quot;qsmk1&quot;) %&gt;% select(estimate, conf_low = conf.low, conf_high = conf.high) kable(v, nsmall = 1) estimate conf_low conf_high 3.5 2.6 4.3 15.2 Propensity scores Fit logistic regression model for propensity scores. fit &lt;- glm( qsmk ~ sex + poly(age, 2) + race + education + poly(wt71, 2) + + poly(smokeintensity, 2) + poly(smokeyrs, 2) + active + exercise, family = binomial(), data = nhefs ) broom::tidy(fit) #&gt; # A tibble: 19 × 5 #&gt; term estimate std.error statistic p.value #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 (Intercept) -1.04 0.194 -5.35 0.0000000897 #&gt; 2 sex1 -0.508 0.148 -3.42 0.000617 #&gt; 3 poly(age, 2)1 23.6 4.89 4.83 0.00000134 #&gt; 4 poly(age, 2)2 -3.76 3.15 -1.19 0.233 #&gt; 5 race1 -0.850 0.206 -4.13 0.0000363 #&gt; 6 education2 -0.0983 0.191 -0.516 0.606 #&gt; 7 education3 0.0157 0.171 0.0920 0.927 #&gt; 8 education4 -0.0425 0.264 -0.161 0.872 #&gt; 9 education5 0.380 0.220 1.72 0.0850 #&gt; 10 poly(wt71, 2)1 3.87 2.64 1.47 0.143 #&gt; # … with 9 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows Add propensity scores to data. nhefs &lt;- nhefs %&gt;% mutate(propensity = predict(fit, type = &quot;response&quot;)) Individuals with the lowest and highest propensity scores. nhefs %&gt;% select(seqn, propensity, qsmk) %&gt;% arrange(propensity) %&gt;% slice(1, n()) %&gt;% kable(nsmall = 3) seqn propensity qsmk 22941 0.053 0 24949 0.793 1 Consistent with their propensity scores, individual 22941 did not quit smoking and individual 24949 did. Distribution of propensity scores for non-quitters and quitters. qsmk_labels &lt;- c(&quot;0&quot; = &quot;Non-quitters&quot;, &quot;1&quot; = &quot;Quitters&quot;) means &lt;- nhefs %&gt;% group_by(qsmk) %&gt;% summarize(propensity_mean = mean(propensity)) nhefs %&gt;% ggplot(aes(propensity)) + geom_histogram(binwidth = 0.05, boundary = 0.025) + geom_vline(aes(xintercept = propensity_mean), data = means, color = &quot;red&quot;) + scale_x_continuous(breaks = scales::breaks_width(0.1)) + facet_grid(rows = vars(qsmk), labeller = labeller(qsmk = qsmk_labels)) + labs( title = &quot;Distribution of propensity scores for non-quitters and quitters&quot;, subtitle = &quot;Red lines indicate mean propensity score for group&quot;, x = &quot;Propensity score&quot;, y = &quot;Number of subjects&quot; ) Mean propensity score for group. kable(means, nsmall = 3) qsmk propensity_mean 0 0.245 1 0.312 As expected, those who did not quit smoking had, on average, a lower estimated probability of quitting (0.245) than those who did quit (0.312). Mean propensity scores vs. proportion for subjects who quit smoking. v &lt;- nhefs %&gt;% group_by(bin = cut_width(propensity, width = 0.05, boundary = 0.025)) %&gt;% summarize( propensity_mean = mean(propensity), qsmk_mean = mean(as.double(qsmk) - 1), n = n() ) %&gt;% filter(n &gt; 1) v %&gt;% ggplot(aes(propensity_mean, qsmk_mean, size = n)) + geom_point() + geom_abline() + scale_x_continuous(breaks = scales::breaks_width(0.1)) + scale_y_continuous(breaks = scales::breaks_width(0.1)) + coord_fixed() + labs( title = &quot;Mean propensity scores vs. proportion for subjects who quit smoking&quot;, x = &quot;Mean propensity score for bin&quot;, y = &quot;Proportion of subjects in bin who quit smoking&quot; ) For the bins in the histogram, this plot shows that the mean propensity score for each bin is fairly close to the actual proportion of subjects in the bin who quit smoking. 15.3 Propensity stratification and standardization Individual 22005 is the only person with a propensity score near 0.6563. nhefs %&gt;% filter(near(propensity, 0.6563, tol = 0.0001)) %&gt;% select(seqn, propensity) %&gt;% kable(nsmall = 4) seqn propensity 22005 0.6563 Add column for propensity score deciles. nhefs &lt;- nhefs %&gt;% arrange(propensity, seqn) %&gt;% mutate( decile = cut_number(propensity, n = 10, labels = FALSE) %&gt;% as.factor() ) %&gt;% arrange(seqn) Number of individuals in each decile. nhefs %&gt;% count(decile) %&gt;% kable() decile n 1 163 2 163 3 163 4 163 5 163 6 162 7 163 8 163 9 163 10 163 Fit linear regression with decile interaction. fit &lt;- lm(wt82_71 ~ qsmk * decile, data = nhefs) broom::tidy(fit) #&gt; # A tibble: 20 × 5 #&gt; term estimate std.error statistic p.value #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 (Intercept) 4.00 0.630 6.34 3.04e-10 #&gt; 2 qsmk1 -0.0147 2.39 -0.00613 9.95e- 1 #&gt; 3 decile2 -1.09 0.916 -1.19 2.34e- 1 #&gt; 4 decile3 -1.38 0.918 -1.51 1.32e- 1 #&gt; 5 decile4 -0.521 0.926 -0.562 5.74e- 1 #&gt; 6 decile5 -1.90 0.940 -2.02 4.39e- 2 #&gt; 7 decile6 -2.15 0.954 -2.25 2.44e- 2 #&gt; 8 decile7 -2.44 0.949 -2.57 1.04e- 2 #&gt; 9 decile8 -3.71 0.974 -3.81 1.44e- 4 #&gt; 10 decile9 -4.89 1.03 -4.73 2.44e- 6 #&gt; # … with 10 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows Estimate ATE with 95% confidence interval for decile. ate &lt;- function(fit, decile) { if (decile == 1) { contrast &lt;- c(qsmk1 = 1) } else { contrast &lt;- c(1, 1) names(contrast) &lt;- c(&quot;qsmk1&quot;, str_c(&quot;qsmk1:decile&quot;, decile)) } linfct &lt;- matrix(0, ncol = length(coef(fit))) colnames(linfct) &lt;- names(coef(fit)) linfct[, names(contrast)] &lt;- contrast multcomp::glht(fit, linfct = linfct) %&gt;% broom::tidy(conf.int = TRUE) %&gt;% select(estimate, conf_low = conf.low, conf_high = conf.high) %&gt;% add_column(decile, .before = &quot;estimate&quot;) } Estimates of ATE with 95% confidence intervals for all deciles. ate_decile &lt;- 1:10 %&gt;% map_dfr(~ ate(fit, decile = .)) %&gt;% mutate(across(decile, as.factor)) ate_decile %&gt;% kable(nsmall = 1) decile estimate conf_low conf_high 1 0.0 -4.7 4.7 2 4.1 0.9 7.4 3 6.5 3.4 9.7 4 2.3 -0.6 5.2 5 4.1 1.4 6.8 6 4.5 1.8 7.2 7 4.3 1.5 7.1 8 3.6 0.9 6.2 9 2.3 -0.2 4.8 10 2.2 -0.2 4.7 Estimated average treatment effect for each propensity score decile. v &lt;- nhefs %&gt;% group_by(decile) %&gt;% summarize(propensity_mean = mean(propensity)) %&gt;% left_join(ate_decile, by = &quot;decile&quot;) v %&gt;% ggplot(aes(propensity_mean, estimate)) + geom_pointrange(aes(ymin = conf_low, ymax = conf_high)) + labs( title = &quot;Estimated average treatment effect for each propensity score decile&quot;, subtitle = &quot;Range indicates 95% confidence interval&quot;, x = &quot;Mean propensity score for decile&quot;, y = &quot;Estimated average treatment effect for decile (kg)&quot; ) Fit linear regression without decile interaction. fit &lt;- lm(wt82_71 ~ qsmk + decile, data = nhefs) broom::tidy(fit) #&gt; # A tibble: 11 × 5 #&gt; term estimate std.error statistic p.value #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 (Intercept) 3.75 0.609 6.16 9.29e-10 #&gt; 2 qsmk1 3.50 0.457 7.66 3.28e-14 #&gt; 3 decile2 -0.739 0.861 -0.858 3.91e- 1 #&gt; 4 decile3 -0.618 0.861 -0.718 4.73e- 1 #&gt; 5 decile4 -0.520 0.858 -0.606 5.44e- 1 #&gt; 6 decile5 -1.49 0.859 -1.73 8.34e- 2 #&gt; 7 decile6 -1.62 0.868 -1.87 6.16e- 2 #&gt; 8 decile7 -1.99 0.868 -2.29 2.23e- 2 #&gt; 9 decile8 -3.44 0.875 -3.94 8.61e- 5 #&gt; 10 decile9 -5.15 0.885 -5.83 6.91e- 9 #&gt; # … with 1 more row #&gt; # ℹ Use `print(n = ...)` to see more rows Propensity score stratification - Decile: estimate of ATE with 95% confidence interval. v &lt;- broom::tidy(fit, conf.int = TRUE) %&gt;% filter(term == &quot;qsmk1&quot;) %&gt;% select(estimate, conf_low = conf.low, conf_high = conf.high) kable(v, nsmall = 1) estimate conf_low conf_high 3.5 2.6 4.4 Fit linear regression with continuous propensity score. fit &lt;- lm(wt82_71 ~ qsmk + propensity, data = nhefs) broom::tidy(fit) #&gt; # A tibble: 3 × 5 #&gt; term estimate std.error statistic p.value #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 (Intercept) 5.59 0.483 11.6 8.16e-30 #&gt; 2 qsmk1 3.55 0.457 7.76 1.47e-14 #&gt; 3 propensity -14.8 1.76 -8.43 7.55e-17 Propensity score stratification - Continuous: estimate of ATE with 95% confidence interval. v &lt;- broom::tidy(fit, conf.int = TRUE) %&gt;% filter(term == &quot;qsmk1&quot;) %&gt;% select(estimate, conf_low = conf.low, conf_high = conf.high) kable(v, nsmall = 1) estimate conf_low conf_high 3.6 2.7 4.4 Data with values for wt82_71. nhefs_censored &lt;- nhefs %&gt;% drop_na(wt82_71) ATE using fit on sample of data. ate &lt;- function(data, sample_rows) { fit &lt;- lm(wt82_71 ~ qsmk + propensity, data = data %&gt;% slice(sample_rows)) mean(predict(fit, newdata = nhefs %&gt;% mutate(qsmk = &quot;1&quot;))) - mean(predict(fit, newdata = nhefs %&gt;% mutate(qsmk = &quot;0&quot;))) } Estimate of ATE. estimate &lt;- ate(data = nhefs_censored, sample_rows = 1:nrow(nhefs_censored)) tibble(estimate) %&gt;% kable(nsmall = 1) estimate 3.6 We will now use bootstrapping to obtain a confidence interval for this estimate. Perform bootstrap resampling. set.seed(231) n_boot &lt;- 1e4 boot_out &lt;- boot::boot(data = nhefs_censored, statistic = ate, R = n_boot) Distribution of average treatment effect. tibble(ate = boot_out$t) %&gt;% ggplot(aes(ate)) + geom_histogram(binwidth = 0.1, boundary = 0) + labs( title = &quot;Distribution of average treatment effect&quot;, x = &quot;Average treatment effect&quot;, y = &quot;Count&quot; ) Propensity score standardization: estimate of ATE with 95% confidence interval. Confidence interval calculated using bias-corrected and accelerated (BCa) method. v &lt;- broom::tidy(boot_out, conf.int = TRUE, conf.method = &quot;bca&quot;) %&gt;% transmute(estimate, conf_low = conf.low, conf_high = conf.high) kable(v, nsmall = 1) estimate conf_low conf_high 3.6 2.6 4.5 "],["16.html", "16 Instrumental variable estimation 16.1 The three instrumental conditions 16.2 The usual IV estimand 16.5 The three instrumental conditions revisited", " 16 Instrumental variable estimation # Packages library(tidyverse) # Parameters # NHEFS data file_nhefs &lt;- here::here(&quot;data/nhefs.rds&quot;) # Round and format vector round_format &lt;- function(x, nsmall = 2, ...) { format(round(x, digits = nsmall), nsmall = nsmall, ...) } # Print tibble kable &lt;- function(x, cols = where(is.double), nsmall = 2, align = &quot;r&quot;, ...) { x %&gt;% mutate(across({{cols}}, round_format, nsmall = nsmall)) %&gt;% knitr::kable(align = align, ...) %&gt;% kableExtra::kable_styling(full_width = FALSE, position = &quot;left&quot;) } #=============================================================================== # NHEFS data with qsmk as a double nhefs &lt;- read_rds(file_nhefs) %&gt;% mutate(qsmk = as.double(qsmk) - 1) # NHEFS censored to remove missing weight and price measurements in 1982 nhefs_censored &lt;- nhefs %&gt;% drop_na(wt82, wt82_71, price82) 16.1 The three instrumental conditions In the following, we will consider price82 as an instrumental variable: price82: Average tobacco price in state of residence in 1982 ($USD 2008) Range of tobacco prices. summary(nhefs_censored$price82) #&gt; Min. 1st Qu. Median Mean 3rd Qu. Max. #&gt; 1.452 1.740 1.815 1.806 1.868 2.103 The prices ranged from $1.45 to $2.10 with an average of around $1.81. Distribution of tobacco prices. nhefs_censored %&gt;% ggplot(aes(price82)) + geom_histogram(binwidth = 0.05, boundary = 0) + geom_vline(xintercept = mean(nhefs_censored$price82), color = &quot;red&quot;) + scale_x_continuous(breaks = scales::breaks_width(0.1)) + labs( title = &quot;Distribution of tobacco prices&quot;, subtitle = &quot;Red line indicates mean price&quot;, x = &quot;Price of tobacco&quot;, y = &quot;Count&quot; ) Proportion of subjects who quit smoking vs. mean price of tobacco. v &lt;- nhefs_censored %&gt;% arrange(price82, seqn) %&gt;% mutate(decile = cut_number(price82, n = 10)) %&gt;% group_by(decile) %&gt;% summarize(across(c(price82, qsmk), mean)) v %&gt;% ggplot(aes(price82, qsmk)) + geom_point() + scale_y_continuous(breaks = scales::breaks_width(0.02)) + labs( title = &quot;Proportion of subjects who quit smoking vs. mean price of tobacco&quot;, subtitle = &quot;By price decile&quot;, x = &quot;Mean price of tobacco in decile&quot;, y = &quot;Proportion of subjects who quit smoking in decile &quot; ) By price decile, there is a very week association, if any, of the mean price of tobacco and the proportion of subjects who quit smoking. Add variable highprice to indicate that price82 is greater that 1.5. nhefs_censored &lt;- nhefs_censored %&gt;% mutate( highprice = case_when( price82 &lt;= 1.5 ~ 0, price82 &gt; 1.5 ~ 1, TRUE ~ NA_real_ ) %&gt;% as.factor() ) Percentage of those who quit smoking by price group. v &lt;- nhefs_censored %&gt;% group_by(highprice) %&gt;% summarize(qsmk_pct = 100 * mean(qsmk)) kable(v, nsmall = 1) highprice qsmk_pct 0 19.5 1 25.8 25.8% of those in the highprice = 1 group quit smoking, and 19.5% of those in the highprice = 0 group quit smoking. The risk difference is therefore 6.3%. 16.2 The usual IV estimand Mean values of weight gain (wt82_71) and whether subject quit smoking (qsmk) by price group. v &lt;- nhefs_censored %&gt;% group_by(highprice) %&gt;% summarize(across(c(wt82_71, qsmk), mean)) kable(v, nsmall = 4) highprice wt82_71 qsmk 0 2.5357 0.1951 1 2.6860 0.2578 The differences in the means. v &lt;- v %&gt;% summarize( wt82_71_diff = wt82_71[highprice == &quot;1&quot;] - wt82_71[highprice == &quot;0&quot;], qsmk_diff = qsmk[highprice == &quot;1&quot;] - qsmk[highprice == &quot;0&quot;] ) kable(v, nsmall = 4) wt82_71_diff qsmk_diff 0.1503 0.0627 Estimate of ATE. v %&gt;% summarize(estimate = wt82_71_diff / qsmk_diff) %&gt;% kable(nsmall = 1) estimate 2.4 Equivalent estimate of ATE calculated using two saturated linear models. tibble( estimate = coef(lm(wt82_71 ~ highprice, data = nhefs_censored))[&quot;highprice1&quot;] / coef(lm(qsmk ~ highprice, data = nhefs_censored))[&quot;highprice1&quot;] ) %&gt;% kable(nsmall = 1) estimate 2.4 Fit two-stage least-squares regression. fit &lt;- ivreg::ivreg(wt82_71 ~ qsmk | highprice, data = nhefs_censored) summary(fit) #&gt; #&gt; Call: #&gt; ivreg::ivreg(formula = wt82_71 ~ qsmk | highprice, data = nhefs_censored) #&gt; #&gt; Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -43.34863 -4.00206 -0.02712 4.17040 46.47022 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error t value Pr(&gt;|t|) #&gt; (Intercept) 2.068 5.085 0.407 0.684 #&gt; qsmk 2.396 19.840 0.121 0.904 #&gt; #&gt; Diagnostic tests: #&gt; df1 df2 statistic p-value #&gt; Weak instruments 1 1474 0.822 0.365 #&gt; Wu-Hausman 1 1473 0.000 0.989 #&gt; Sargan 0 NA NA NA #&gt; #&gt; Residual standard error: 7.856 on 1474 degrees of freedom #&gt; Multiple R-Squared: 0.02129, Adjusted R-squared: 0.02062 #&gt; Wald test: 0.01459 on 1 and 1474 DF, p-value: 0.9039 Here’s how to interpret the diagnostic tests: Weak instruments: A good instrumental variable is highly correlated with endogenous predictor variables and uncorrelated with the errors. This would be indicated with a high value for the statistic and a low p-value. Thus, highprice does not appear to be a good instrumental value. Wu-Hausman: Ordinary least squares can be inconsistent when predictor variables are correlated with the errors. This would be indicated with a high value for the statistic and a low p-value. This does not appear to be the case. The F-statistic for the first-stage model is less than 10. lm(qsmk ~ highprice, data = nhefs_censored) %&gt;% broom::glance() %&gt;% select(f_statistic = statistic) %&gt;% kable(nsmall = 1) f_statistic 0.8 Estimate of ATE with 95% confidence interval. broom::tidy(fit, conf.int = TRUE) %&gt;% filter(term == &quot;qsmk&quot;) %&gt;% select(estimate, conf_low = conf.low, conf_high = conf.high) %&gt;% kable(nsmall = 1) estimate conf_low conf_high 2.4 -36.5 41.3 The confidence interval is very large. We will now estimate the ATE using g-estimation. For potential counterfactual (psi), calculate logistic regression coefficient (alpha) and its p-value (p_value). g_est &lt;- function(psi) { geepack::geeglm( highprice ~ h, family = binomial(), data = nhefs_censored %&gt;% mutate( highprice = as.double(highprice) - 1, h = wt82_71 - psi * qsmk ), id = seqn ) %&gt;% broom::tidy() %&gt;% filter(term == &quot;h&quot;) %&gt;% transmute(psi, alpha = estimate, p_value = p.value) } To estimate the ATE, use optimization to search for the value of psi with alpha value closest to 0. f &lt;- function(psi) { abs(g_est(psi)$alpha) } v &lt;- optimize(f, interval = c(-50, 50)) estimate &lt;- v$minimum tibble(estimate, `abs(alpha)` = v$objective) %&gt;% kable(nsmall = 3) estimate abs(alpha) 2.396 0.000 Thus the estimate of the ATE is consistent with the value above. tibble(estimate) %&gt;% kable(nsmall = 1) estimate 2.4 The method of section 14.6 to find a confidence interval for the ATE does not work in this case, due to the inability of reducing the p-value to below 0.05. 16.5 The three instrumental conditions revisited Use two-stage least-squares regression to calculate ATE with 95% confidence interval with highprice defined using price. ate &lt;- function(price) { ivreg::ivreg( wt82_71 ~ qsmk | highprice, data = nhefs_censored %&gt;% mutate( highprice = case_when( price82 &lt;= price ~ 0, price82 &gt; price ~ 1, TRUE ~ NA_real_ ) %&gt;% as.factor() ) ) %&gt;% broom::tidy(conf.int = TRUE) %&gt;% filter(term == &quot;qsmk&quot;) %&gt;% select(estimate, conf_low = conf.low, conf_high = conf.high) %&gt;% add_column(price, .before = &quot;estimate&quot;) } Estimates of ATEs with 95% confidence intervals for different prices. seq(1.6, 1.9, 0.1) %&gt;% map_dfr(ate) %&gt;% mutate(price = str_c(&quot;$&quot;, round_format(price, nsmall = 2))) %&gt;% kable(nsmall = 1) price estimate conf_low conf_high $1.60 41.3 -282.3 364.8 $1.70 -40.9 -409.2 327.4 $1.80 -21.1 -76.9 34.7 $1.90 -12.8 -59.2 33.6 The estimates, in kilograms, are too large to be plausible, and the confidence intervals are very large. Fit two-stage least-squares regression using variables and model from section 15.1. We will assume that qsmk is the only endogenous predictor variable. fit &lt;- ivreg::ivreg( wt82_71 ~ sex + poly(age, 2) + race + education + poly(wt71, 2) + poly(smokeintensity, 2) + poly(smokeyrs, 2) + active + exercise | qsmk | highprice, data = nhefs_censored ) summary(fit) #&gt; #&gt; Call: #&gt; ivreg::ivreg(formula = wt82_71 ~ sex + poly(age, 2) + race + #&gt; education + poly(wt71, 2) + poly(smokeintensity, 2) + poly(smokeyrs, #&gt; 2) + active + exercise | qsmk | highprice, data = nhefs_censored) #&gt; #&gt; Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -43.7423 -4.5482 -0.4517 3.8464 47.2542 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error t value Pr(&gt;|t|) #&gt; (Intercept) 3.99398 7.80159 0.512 0.6088 #&gt; qsmk -3.13250 32.63876 -0.096 0.9236 #&gt; sex1 -1.97116 2.75323 -0.716 0.4741 #&gt; poly(age, 2)1 -59.34351 112.31649 -0.528 0.5973 #&gt; poly(age, 2)2 -43.08971 26.53034 -1.624 0.1046 #&gt; race1 -0.47187 5.03253 -0.094 0.9253 #&gt; education2 0.60686 0.71879 0.844 0.3986 #&gt; education3 0.60944 0.94965 0.642 0.5211 #&gt; education4 1.62590 1.06644 1.525 0.1276 #&gt; education5 0.46648 3.45391 0.135 0.8926 #&gt; poly(wt71, 2)1 -59.62715 21.53747 -2.769 0.0057 ** #&gt; poly(wt71, 2)2 -9.39097 16.78443 -0.560 0.5759 #&gt; poly(smokeintensity, 2)1 -6.35880 69.69741 -0.091 0.9273 #&gt; poly(smokeintensity, 2)2 -0.02664 52.68866 -0.001 0.9996 #&gt; poly(smokeyrs, 2)1 0.03413 65.54988 0.001 0.9996 #&gt; poly(smokeyrs, 2)2 -0.80088 33.44159 -0.024 0.9809 #&gt; active1 -0.97707 0.48369 -2.020 0.0436 * #&gt; active2 -0.20673 1.20222 -0.172 0.8635 #&gt; exercise1 0.53695 2.28816 0.235 0.8145 #&gt; exercise2 0.63151 2.39327 0.264 0.7919 #&gt; #&gt; Diagnostic tests: #&gt; df1 df2 statistic p-value #&gt; Weak instruments 1 1456 0.327 0.568 #&gt; Wu-Hausman 1 1455 0.048 0.826 #&gt; Sargan 0 NA NA NA #&gt; #&gt; Residual standard error: 7.913 on 1456 degrees of freedom #&gt; Multiple R-Squared: 0.01914, Adjusted R-squared: 0.006341 #&gt; Wald test: 8.562 on 19 and 1456 DF, p-value: &lt; 2.2e-16 The weak instruments diagnostic test again indicates that highprice does not appear to be a good instrumental value. Estimate of ATE with 95% confidence interval. broom::tidy(fit, conf.int = TRUE) %&gt;% filter(term == &quot;qsmk&quot;) %&gt;% select(estimate, conf_low = conf.low, conf_high = conf.high) %&gt;% kable(nsmall = 1) estimate conf_low conf_high -3.1 -67.2 60.9 The confidence interval is even larger than with the earlier two-stage least-squares regression. "],["17.html", "17 Causal survival analysis 17.1 Hazards and risks 17.2 From hazards to risks 17.4 IP weighting of marginal structural models 17.5 The parametric g-formula 17.6 G-estimation of structural nested models", " 17 Causal survival analysis # Packages library(tidyverse) # Parameters # NHEFS data file_nhefs &lt;- here::here(&quot;data/nhefs.rds&quot;) # Round and format vector round_format &lt;- function(x, nsmall = 2, ...) { format(round(x, digits = nsmall), nsmall = nsmall, ...) } # Print tibble kable &lt;- function(x, cols = where(is.double), nsmall = 2, align = &quot;r&quot;, ...) { x %&gt;% mutate(across({{cols}}, round_format, nsmall = nsmall)) %&gt;% knitr::kable(align = align, ...) %&gt;% kableExtra::kable_styling(full_width = FALSE, position = &quot;left&quot;) } # Print min, mean, and max of vector kable_summary &lt;- function(x, nsmall = 2, ...) { tibble(min = min(x), mean = mean(x), max = max(x)) %&gt;% kable(nsmall = nsmall, ...) } #=============================================================================== # NHEFS data with qsmk as a double nhefs &lt;- read_rds(file_nhefs) %&gt;% mutate(qsmk = as.double(qsmk) - 1) 17.1 Hazards and risks In the following, we will use these variables: dadth: Day of death death: Death by 1992 0: No 1: Yes modth: Month of death yrdth: Year of death Number of people in dataset. nrow(nhefs) #&gt; [1] 1629 Range of ages. range(nhefs$age) #&gt; [1] 25 74 The number of people who died by the end of 1992. v &lt;- nhefs %&gt;% count(death) kable(v) death n 0 1311 1 318 Of the 1629 individuals in the dataset, 318 died before the end of 1992, and the remaining 1311 survived. The variables death, yrdth, modth, and dadth. nhefs %&gt;% count(death, !is.na(yrdth), !is.na(modth), !is.na(dadth)) #&gt; # A tibble: 3 × 5 #&gt; death `!is.na(yrdth)` `!is.na(modth)` `!is.na(dadth)` n #&gt; &lt;fct&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;lgl&gt; &lt;int&gt; #&gt; 1 0 FALSE FALSE FALSE 1307 #&gt; 2 0 FALSE TRUE TRUE 4 #&gt; 3 1 TRUE TRUE TRUE 318 Note that four individuals have months and days of death but no year. They are classified by the death variable as having not died. For the following, we will assume that the death variable is correct. The follow-up period began on January 1, 1983 and lasted through December 31, 1992. For those who died, we will add the variable time_death for the month of the follow-up in which they died, ranging from 1 for January 1983 to 120 for December 1992. nhefs &lt;- nhefs %&gt;% mutate( time_death = if_else(death == &quot;1&quot;, 12 * (yrdth - 83) + modth, NA_real_) ) Range of values for time_death. range(nhefs$time_death, na.rm = TRUE) #&gt; [1] 1 120 Number of individuals who died by whether or not they quit smoking (qsmk). v &lt;- nhefs %&gt;% filter(!is.na(time_death)) %&gt;% count(qsmk) kable(cols = NULL, v) qsmk n 0 216 1 102 Of the 318 individuals who died, 216 did not quit smoking and 102 did quit smoking. For each treatment group (qsmk) and each follow-up month, calculate the cumulative deaths (deaths_cum), the number who survived (survived), and the proportion who survived (survival). time_max &lt;- max(nhefs$time_death, na.rm = TRUE) survival_1 &lt;- expand_grid(qsmk = 0:1, time = 0:time_max) %&gt;% left_join( nhefs %&gt;% filter(death == &quot;1&quot;) %&gt;% count(qsmk, time = time_death, name = &quot;deaths&quot;), by = c(&quot;qsmk&quot;, &quot;time&quot;) ) %&gt;% replace_na(list(deaths = 0)) %&gt;% group_by(qsmk) %&gt;% mutate( deaths_cum = cumsum(deaths), survived = sum(nhefs$qsmk == first(qsmk)) - deaths_cum, survival = survived / sum(nhefs$qsmk == first(qsmk)) ) %&gt;% ungroup() survival_1 #&gt; # A tibble: 242 × 6 #&gt; qsmk time deaths deaths_cum survived survival #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 0 0 0 0 1201 1 #&gt; 2 0 1 0 0 1201 1 #&gt; 3 0 2 0 0 1201 1 #&gt; 4 0 3 0 0 1201 1 #&gt; 5 0 4 1 1 1200 0.999 #&gt; 6 0 5 1 2 1199 0.998 #&gt; 7 0 6 0 2 1199 0.998 #&gt; 8 0 7 1 3 1198 0.998 #&gt; 9 0 8 2 5 1196 0.996 #&gt; 10 0 9 0 5 1196 0.996 #&gt; # … with 232 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows Figure 17.1. survival_plot_details &lt;- function(y_quitters = 0.74) { list( annotate( &quot;text&quot;, x = 119, y = c(0.87, y_quitters), hjust = 1, label = c(&quot;Non-quitters&quot;, &quot;Quitters&quot;) ), coord_cartesian(ylim = c(0.5, 1)), scale_x_continuous(breaks = scales::breaks_width(20)), theme(legend.position = &quot;none&quot;), labs( x = &quot;Month of follow-up&quot;, y = &quot;Survival probability&quot; ) ) } survival_1 %&gt;% ggplot(aes(time, survival, color = as.factor(qsmk))) + geom_line() + survival_plot_details() + labs(title = &quot;Figure 17.1&quot;) Log-rank test to compare survival curves. test &lt;- nhefs %&gt;% transmute( qsmk, time = replace_na(time_death, replace = time_max), event = as.double(death) - 1 ) %&gt;% survival::survdiff( survival::Surv(time = time, event = event) ~ qsmk, data = . ) broom::glance(test) %&gt;% select(p_value = p.value) %&gt;% kable(nsmall = 3) p_value 0.005 Survival at 120 months. v &lt;- survival_1 %&gt;% filter(time == 120) %&gt;% select(qsmk, survival) v %&gt;% kable(cols = survival, nsmall = 3) qsmk survival 0 0.820 1 0.762 Survival at 120 months was 82.0% among non-quitters and 76.2% among quitters. The risk at 120 months was 18.0% among non-quitters and 23.8% among quitters. Hazard at 120 months. v &lt;- survival_1 %&gt;% mutate( survived_prev = lag(survived), hazard = deaths / survived_prev ) %&gt;% filter(time == 120) %&gt;% select(qsmk, time, deaths, survived_prev, hazard) v %&gt;% kable(cols = hazard, nsmall = 4) qsmk time deaths survived_prev hazard 0 120 1 986 0.0010 1 120 0 326 0.0000 The hazard at 120 months was 0.10% among non-quitters and 0% among quitters. 17.2 From hazards to risks Time-event tibble for person in person-time format. time_event &lt;- function(death, time_death) { stopifnot(death %in% c(&quot;0&quot;, &quot;1&quot;)) if (death == &quot;0&quot;) { tibble(time = seq_len(time_max) - 1, event = 0) } else if (death == &quot;1&quot;) { tibble( time = seq_len(time_death) - 1, event = rep(0:1, c(time_death - 1, 1)) ) } } NHEFS dataset in person-time format. nhefs_pt &lt;- nhefs %&gt;% select(seqn, qsmk, death, time_death) %&gt;% rowwise() %&gt;% mutate(time_event = list(time_event(death, time_death))) %&gt;% unnest(time_event) Number of rows in nhefs_pt. nrow(nhefs_pt) #&gt; [1] 176764 Fit logistic regression for hazards. fit &lt;- glm( event ~ poly(time, 2) + qsmk * poly(time, 2), family = binomial(), data = nhefs_pt ) broom::tidy(fit) #&gt; # A tibble: 6 × 5 #&gt; term estimate std.error statistic p.value #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 (Intercept) -6.44 0.0698 -92.2 0 #&gt; 2 poly(time, 2)1 71.0 30.8 2.30 0.0212 #&gt; 3 poly(time, 2)2 -56.5 30.1 -1.88 0.0604 #&gt; 4 qsmk 0.306 0.125 2.45 0.0145 #&gt; 5 poly(time, 2)1:qsmk -99.0 57.3 -1.73 0.0843 #&gt; 6 poly(time, 2)2:qsmk -72.6 56.1 -1.29 0.196 Calculate survival curves. survival &lt;- function(fit) { expand_grid(qsmk = 0:1, time = 0:time_max) %&gt;% group_by(qsmk) %&gt;% mutate( survival = cumprod( 1 - predict(fit, newdata = tibble(qsmk, time), type = &quot;response&quot;) ) %&gt;% lag(default = 1) ) %&gt;% ungroup() } Figure 17.4. survival_2 &lt;- survival(fit) survival_2 %&gt;% ggplot(aes(time, survival, color = as.factor(qsmk))) + geom_line() + survival_plot_details() + labs(title = &quot;Figure 17.4&quot;) Superposition of Figures 17.1 and 17.4. ggplot(mapping = aes(time, survival)) + geom_line(aes(group = qsmk), data = survival_1, color = &quot;grey60&quot;) + geom_line(aes(color = as.factor(qsmk)), data = survival_2) + survival_plot_details() + labs(title = &quot;Superposition of Figures 17.1 and 17.4&quot;) 17.4 IP weighting of marginal structural models Stabilized IP weights for treatment. ip_numerator &lt;- case_when( nhefs$qsmk == 0 ~ 1 - mean(nhefs$qsmk), nhefs$qsmk == 1 ~ mean(nhefs$qsmk), TRUE ~ NA_real_ ) fit_denominator &lt;- glm( qsmk ~ sex + poly(age, 2) + race + education + poly(wt71, 2) + poly(smokeintensity, 2) + poly(smokeyrs, 2) + active + exercise, family = binomial(), data = nhefs ) ip_denominator &lt;- case_when( nhefs$qsmk == 0 ~ 1 - predict(fit_denominator, type = &quot;response&quot;), nhefs$qsmk == 1 ~ predict(fit_denominator, type = &quot;response&quot;), TRUE ~ NA_real_ ) ip_sw_a &lt;- ip_numerator / ip_denominator kable_summary(ip_sw_a) min mean max 0.33 1.00 4.21 NHEFS dataset with weights in person-time format. nhefs_pt &lt;- nhefs %&gt;% transmute(seqn, qsmk, weight = ip_sw_a, death, time_death) %&gt;% rowwise() %&gt;% mutate(time_event = list(time_event(death, time_death))) %&gt;% unnest(time_event) Fit logistic regression for hazards. fit &lt;- glm( event ~ poly(time, 2) + qsmk * poly(time, 2), family = binomial(), data = nhefs_pt, weights = weight ) broom::tidy(fit) #&gt; # A tibble: 6 × 5 #&gt; term estimate std.error statistic p.value #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 (Intercept) -6.34 0.0669 -94.8 0 #&gt; 2 poly(time, 2)1 73.4 29.5 2.49 0.0128 #&gt; 3 poly(time, 2)2 -53.2 28.8 -1.85 0.0649 #&gt; 4 qsmk -0.0351 0.135 -0.261 0.794 #&gt; 5 poly(time, 2)1:qsmk -82.8 62.0 -1.34 0.181 #&gt; 6 poly(time, 2)2:qsmk -94.7 60.9 -1.56 0.120 Figure 17.6. survival_3 &lt;- survival(fit) survival_3 %&gt;% ggplot(aes(time, survival, color = as.factor(qsmk))) + geom_line() + survival_plot_details(y_quitters = 0.78) + labs(title = &quot;Figure 17.6&quot;) Superposition of Figures 17.4 and 17.6. ggplot(mapping = aes(time, survival)) + geom_line(aes(group = qsmk), data = survival_2, color = &quot;grey60&quot;) + geom_line(aes(color = as.factor(qsmk)), data = survival_3) + survival_plot_details() + labs(title = &quot;Superposition of Figures 17.4 and 17.6&quot;) Survival at 120 months. v &lt;- survival_3 %&gt;% filter(time == 120) %&gt;% select(qsmk, survival) v %&gt;% kable(cols = survival, nsmall = 3) qsmk survival 0 0.805 1 0.807 Survival at 120 months was 80.5% among non-quitters and 80.7% among quitters for a difference of 0.2%. Calculate survival difference at 120 months and the largest absolute value of the differences for all months. If boot = TRUE (the default), use bootstrap sample of data. If boot = FALSE, use full dataset. survival_diff &lt;- function(boot = TRUE) { data &lt;- nhefs %&gt;% transmute(seqn, qsmk, weight = ip_sw_a, death, time_death) %&gt;% { if (isTRUE(boot)) { slice_sample(., prop = 1, replace = TRUE) } else { . } } %&gt;% rowwise() %&gt;% mutate(time_event = list(time_event(death, time_death))) %&gt;% unnest(time_event) fit &lt;- glm( event ~ poly(time, 2) + qsmk * poly(time, 2), family = binomial(), data = data, weights = weight ) survival(fit) %&gt;% group_by(time) %&gt;% summarize(diff = survival[qsmk == 1] - survival[qsmk == 0]) %&gt;% summarize( last = last(diff), max = max(abs(diff)) ) } Perform bootstrap resampling. set.seed(231) n_boot &lt;- 500 boot_out &lt;- seq_len(n_boot) %&gt;% map_dfr(~ survival_diff()) Survival difference at 120 months with 95% confidence interval calculated using bootstrap percentile method. v &lt;- tibble( estimate = survival_diff(boot = FALSE)$last, conf_low = quantile(boot_out$last, probs = 0.025), conf_high = quantile(boot_out$last, probs = 0.975) ) kable(v, nsmall = 3) estimate conf_low conf_high 0.002 -0.046 0.046 The survival difference at 120 months was 0.2% with a 95% confidence interval from -4.6% to 4.6% based on 500 bootstrap samples. The largest absolute value of the differences for all months with 95% confidence interval calculated using bootstrap percentile method. Note that this a different measure than the one used in the book. v &lt;- tibble( estimate = survival_diff(boot = FALSE)$max, conf_low = quantile(boot_out$max, probs = 0.025), conf_high = quantile(boot_out$max, probs = 0.975) ) kable(v, nsmall = 3) estimate conf_low conf_high 0.019 0.009 0.060 The largest absolute value of the differences for all months was 1.9% with a 95% confidence interval from 0.9% to 6.0% based on 500 bootstrap samples. 17.5 The parametric g-formula NHEFS dataset in person-time format. nhefs_pt &lt;- nhefs %&gt;% select( qsmk, death, sex, age, race, education, wt71, smokeintensity, smkintensity82_71, smokeyrs, active, exercise, time_death ) %&gt;% rowwise() %&gt;% mutate(time_event = list(time_event(death, time_death))) %&gt;% unnest(time_event) Fit logistic regression for hazards. fit &lt;- glm( event ~ poly(time, 2) + qsmk * poly(time, 2) + sex + poly(age, 2) + race + education + poly(wt71, 2) + poly(smokeintensity, 2) + smkintensity82_71 + poly(smokeyrs, 2) + active + exercise, family = binomial(), data = nhefs_pt ) broom::tidy(fit) #&gt; # A tibble: 25 × 5 #&gt; term estimate std.error statistic p.value #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 (Intercept) -6.70 0.199 -33.7 3.14e-249 #&gt; 2 poly(time, 2)1 130. 31.2 4.16 3.13e- 5 #&gt; 3 poly(time, 2)2 -52.9 30.2 -1.75 8.00e- 2 #&gt; 4 qsmk 0.0296 0.179 0.165 8.69e- 1 #&gt; 5 sex1 -0.437 0.141 -3.10 1.93e- 3 #&gt; 6 poly(age, 2)1 392. 64.7 6.06 1.38e- 9 #&gt; 7 poly(age, 2)2 -4.86 32.7 -0.149 8.82e- 1 #&gt; 8 race1 0.0524 0.173 0.302 7.63e- 1 #&gt; 9 education2 -0.140 0.157 -0.895 3.71e- 1 #&gt; 10 education3 -0.433 0.153 -2.84 4.50e- 3 #&gt; # … with 15 more rows #&gt; # ℹ Use `print(n = ...)` to see more rows Calculate survival curve for individual. time_survival &lt;- function(fit, data, qsmk) { tibble( time = 0:time_max, survival = cumprod( 1 - predict(fit, newdata = tibble(data, qsmk, time), type = &quot;response&quot;) ) %&gt;% lag(default = 1) ) } Calculate survival curves for each individual and then average. survival_4 &lt;- nhefs %&gt;% select( seqn, sex, age, race, education, wt71, smokeintensity, smkintensity82_71, smokeyrs, active, exercise ) %&gt;% expand_grid(qsmk = 0:1) %&gt;% nest(data = !c(seqn, qsmk)) %&gt;% rowwise() %&gt;% transmute( qsmk, time_survival = list(time_survival(fit = fit, data = data, qsmk = qsmk)) ) %&gt;% unnest(time_survival) %&gt;% group_by(qsmk, time) %&gt;% summarize(across(survival, mean)) %&gt;% ungroup() Figure 17.7. survival_4 %&gt;% ggplot(aes(time, survival, color = as.factor(qsmk))) + geom_line() + survival_plot_details(y_quitters = 0.78) + labs(title = &quot;Figure 17.7&quot;) Superposition of Figures 17.6 and 17.7. ggplot(mapping = aes(time, survival)) + geom_line(aes(group = qsmk), data = survival_3, color = &quot;grey60&quot;) + geom_line(aes(color = as.factor(qsmk)), data = survival_4) + survival_plot_details(y_quitters = 0.78) + labs(title = &quot;Superposition of Figures 17.6 and 17.7&quot;) The survival curves from the two figures are coincident. Survival at 120 months. v &lt;- survival_4 %&gt;% filter(time == 120) %&gt;% select(qsmk, survival) v %&gt;% kable(cols = survival, nsmall = 3) qsmk survival 0 0.806 1 0.804 Survival at 120 months was 80.6% among non-quitters and 80.4% among quitters for a difference of -0.3% (rounded from -0.253%). Calculate survival difference at 120 months and the largest absolute value of the differences for all months. If boot = TRUE (the default), use bootstrap sample of data. If boot = FALSE, use full dataset. survival_diff &lt;- function(boot = TRUE) { v &lt;- nhefs %&gt;% select( qsmk, death, sex, age, race, education, wt71, smokeintensity, smkintensity82_71, smokeyrs, active, exercise, time_death ) %&gt;% { if (isTRUE(boot)) { slice_sample(., prop = 1, replace = TRUE) } else { . } } %&gt;% mutate(row = row_number()) data &lt;- v %&gt;% rowwise() %&gt;% mutate(time_event = list(time_event(death, time_death))) %&gt;% unnest(time_event) fit &lt;- glm( event ~ poly(time, 2) + qsmk * poly(time, 2) + sex + poly(age, 2) + race + education + poly(wt71, 2) + poly(smokeintensity, 2) + smkintensity82_71 + poly(smokeyrs, 2) + active + exercise, family = binomial(), data = data ) v %&gt;% select(!c(qsmk, death, time_death)) %&gt;% expand_grid(qsmk = 0:1) %&gt;% nest(data = !c(row, qsmk)) %&gt;% rowwise() %&gt;% transmute( qsmk, time_survival = list(time_survival(fit = fit, data = data, qsmk = qsmk)) ) %&gt;% unnest(time_survival) %&gt;% group_by(qsmk, time) %&gt;% summarize(across(survival, mean)) %&gt;% ungroup() %&gt;% group_by(time) %&gt;% summarize(diff = survival[qsmk == 1] - survival[qsmk == 0]) %&gt;% summarize( last = last(diff), max = max(abs(diff)) ) } Perform bootstrap resampling. set.seed(231) n_boot &lt;- 100 boot_out &lt;- seq_len(n_boot) %&gt;% map_dfr(~ survival_diff()) Survival difference at 120 months with 95% confidence interval calculated using bootstrap percentile method. v &lt;- tibble( estimate = survival_diff(boot = FALSE)$last, conf_low = quantile(boot_out$last, probs = 0.025), conf_high = quantile(boot_out$last, probs = 0.975) ) kable(v, nsmall = 3) estimate conf_low conf_high -0.003 -0.046 0.042 The survival difference at 120 months was -0.3% with a 95% confidence interval from -4.6% to 4.2% based on 100 bootstrap samples. The largest absolute value of the differences for all months with 95% confidence interval calculated using bootstrap percentile method. Note that this a different measure than the one used in the book. v &lt;- tibble( estimate = survival_diff(boot = FALSE)$max, conf_low = quantile(boot_out$max, probs = 0.025), conf_high = quantile(boot_out$max, probs = 0.975) ) kable(v, nsmall = 3) estimate conf_low conf_high 0.020 0.008 0.057 The largest absolute value of the differences for all months was 2.0% with a 95% confidence interval from 0.8% to 5.7% based on 100 bootstrap samples. 17.6 G-estimation of structural nested models Fit logistic regression for treatment. fit &lt;- glm( qsmk ~ sex + poly(age, 2) + race + education + poly(wt71, 2) + poly(smokeintensity, 2) + poly(smokeyrs, 2) + active + exercise, family = binomial(), data = nhefs ) Predict treatment and restrict to individuals who died during follow-up. nhefs_died &lt;- nhefs %&gt;% mutate(qsmk_pred = predict(fit, type = &quot;response&quot;)) %&gt;% drop_na(time_death) %&gt;% select(qsmk, time_death, qsmk_pred) For potential counterfactual (psi), calculate score test statistic. g_est &lt;- function(psi) { nhefs_died %&gt;% mutate( delta = (qsmk == 0 &amp; time_death * exp(-psi) &lt;= time_max) | (qsmk == 1 &amp; time_death * exp(psi) &lt;= time_max), x = delta * (qsmk - qsmk_pred) ) %&gt;% summarize(u = sum(x)^2 / ((n() - 1) * var(x))) %&gt;% pull(u) } 95% quantile of chi-squared distribution with 1 degree of freedom. q_0.95 &lt;- qchisq(p = 0.95, df = 1) q_0.95 #&gt; [1] 3.841459 Score test statistic as a function of potential counterfactual. v &lt;- tibble( psi = seq(-0.3, 0.4, 0.001), u = map_dbl(psi, g_est) ) v %&gt;% ggplot(aes(psi, u)) + geom_line() + geom_hline(yintercept = q_0.95, color = &quot;red&quot;) + scale_x_continuous(breaks = scales::breaks_width(0.1)) + labs( title = &quot;Score test statistic as a function of potential counterfactual&quot;, subtitle = &quot;Red line indicates 95% quantile of chi-squared distribution with 1 degree of freedom&quot;, x = &quot;Potential counterfactual&quot;, y = &quot;Score test statistic&quot; ) The plot appears to be step function, perhaps as a result of individuals being censored depending upon the value of psi. The minimum of the plot. v %&gt;% filter(u == min(u)) #&gt; # A tibble: 9 × 2 #&gt; psi u #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 -0.051 0.00215 #&gt; 2 -0.05 0.00215 #&gt; 3 -0.049 0.00215 #&gt; 4 -0.048 0.00215 #&gt; 5 -0.047 0.00215 #&gt; 6 -0.046 0.00215 #&gt; 7 -0.045 0.00215 #&gt; 8 -0.044 0.00215 #&gt; 9 -0.043 0.00215 All of the values of psi from -0.051 to -0.043 have the same minimum value for the score test statistic. We’ll choose as our estimate the middle of this range. estimate &lt;- v %&gt;% filter(u == min(u)) %&gt;% summarize(estimate = mean(range(psi))) Calculate 95% confidence interval by finding points where plot crosses the red line. conf_low &lt;- tibble( psi = seq(-0.25, -0.2, 0.0001), u = map_dbl(psi, g_est) ) %&gt;% filter((u &gt;= q_0.95 &amp; lead(u) &lt; q_0.95) | (u &lt; q_0.95 &amp; lag(u) &gt;= q_0.95)) %&gt;% summarize(conf_low = mean(range(psi))) conf_high &lt;- tibble( psi = seq(0.3, 0.35, 0.0001), u = map_dbl(psi, g_est) ) %&gt;% filter((u &lt; q_0.95 &amp; lead(u) &gt;= q_0.95) | (u &gt;= q_0.95 &amp; lag(u) &lt; q_0.95)) %&gt;% summarize(conf_high = mean(range(psi))) Estimate of psi with 95% confidence interval. bind_cols(estimate, conf_low, conf_high) %&gt;% kable(nsmall = 3) estimate conf_low conf_high -0.047 -0.223 0.333 "],["results.html", "Results Average treatment effect", " Results # Packages library(tidyverse) # Parameters # Average treatment effect results file_ate &lt;- here::here(&quot;data/ate.rds&quot;) # Round and format vector round_format &lt;- function(x, nsmall = 2, ...) { format(round(x, digits = nsmall), nsmall = nsmall, ...) } # Print tibble kable &lt;- function(x, cols = where(is.double), nsmall = 2, align = &quot;r&quot;, ...) { x %&gt;% mutate(across({{cols}}, round_format, nsmall = nsmall)) %&gt;% knitr::kable(align = align, ...) %&gt;% kableExtra::kable_styling(full_width = FALSE, position = &quot;left&quot;) } #=============================================================================== # Average treatment effect results ate &lt;- read_rds(file_ate) %&gt;% arrange(dataset, section, method) Average treatment effect Chapters 12-15 calculated the average causal effect of smoking cessation (qsmk) on weight gain (wt82_71) using nine different methods. Here we will compare the results. We will separate the methods into two groups. The first group (Censored) used only the censored data, that is the data where wt82_71 was not NA. The second group used the full dataset (Full). Here are the results. ate %&gt;% kable(align = &quot;rllrrr&quot;) section method dataset estimate conf_low conf_high 12.2 IP weighting - Non-stabilized Censored 3.44 2.41 4.47 12.3 IP weighting - Stabilized Censored 3.44 2.41 4.47 15.1 Outcome regression Censored 3.46 2.60 4.32 12.6 IP weighting - Stabilized Full 3.50 2.47 4.53 13.3 Standardization Full 3.52 2.57 4.49 14.5 G-estimation Full 3.45 2.54 4.41 15.3 Propensity score standardization Full 3.55 2.59 4.52 15.3 Propensity score stratification - Continuous Full 3.55 2.65 4.45 15.3 Propensity score stratification - Decile Full 3.50 2.60 4.40 Average treatment effect. ate %&gt;% mutate(method = fct_inorder(method)) %&gt;% ggplot(aes(estimate, method)) + geom_pointrange(aes(xmin = conf_low, xmax = conf_high)) + facet_grid(rows = vars(dataset), scales = &quot;free&quot;, space = &quot;free&quot;) + scale_y_discrete(limits = rev) + labs( title = &quot;Average treatment effect&quot;, x = &quot;Estimate&quot;, y = NULL ) The average treatment effect estimates and 95% confidence intervals are similar for all nine methods. "],["references.html", "References", " References "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
